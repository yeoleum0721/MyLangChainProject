{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bd9054f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk\n",
      "Fy\n",
      "tvly\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:2])\n",
    "\n",
    "UPSTAGE_API_KEY = os.getenv(\"UPSTAGE_API_KEY\")\n",
    "print(UPSTAGE_API_KEY[30:])\n",
    "\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
    "print(TAVILY_API_KEY[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0aed0d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "# from langchain_core.tools import tool\n",
    "from langchain.agents import tool\n",
    "from langchain_community.tools import TavilySearchResults\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_upstage import UpstageEmbeddings\n",
    "from langchain_upstage import ChatUpstage\n",
    "\n",
    "# LangGraph MessagesStateë¼ëŠ” ë¯¸ë¦¬ ë§Œë“¤ì–´ì§„ ìƒíƒœë¥¼ ì‚¬ìš©\n",
    "from langgraph.graph import MessagesState\n",
    "from langchain_core.documents import Document\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "from textwrap import dedent\n",
    "from typing import List, Literal, Tuple\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "from pprint import pprint\n",
    "import re\n",
    "\n",
    "import uuid\n",
    "embeddings_model = UpstageEmbeddings(model=\"solar-embedding-1-large\")\n",
    "\n",
    "cafe_db = FAISS.load_local(\n",
    "    \"./db/cafe_db\", \n",
    "    embeddings_model, \n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "\n",
    "def extract_menu_info(doc: Document) -> dict:\n",
    "    \"\"\"Vector DB ë¬¸ì„œì—ì„œ êµ¬ì¡°í™”ëœ ë©”ë‰´ ì •ë³´ ì¶”ì¶œ\"\"\"\n",
    "    content = doc.page_content\n",
    "    # Documentì˜ metadataì— ë©”ë‰´ëª…ì´ ìˆëŠ” ê²½ìš° ì‚¬ìš©, ì—†ìœ¼ë©´ ë‚´ìš©ì—ì„œ ì¶”ì¶œ ì‹œë„\n",
    "    menu_name = doc.metadata.get('menu_name', 'Unknown')\n",
    "    \n",
    "    # ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ ê°€ê²©, ì„¤ëª… ë“± ì¶”ì¶œ\n",
    "    price_match = re.search(r'â‚©([\\d,]+)', content)\n",
    "    description_match = re.search(r'ì„¤ëª…:\\s*(.+?)(?:\\n|$)', content, re.DOTALL)\n",
    "    \n",
    "    # metadataì— ë©”ë‰´ëª…ì´ ì—†ì„ ê²½ìš° contentì—ì„œ \"ë©”ë‰´:\" ë¶€ë¶„ì„ ì°¾ì•„ì„œ ì‚¬ìš©\n",
    "    if menu_name == 'Unknown':\n",
    "        name_match = re.search(r'ë©”ë‰´:\\s*(.+?)(?:,|$)', content)\n",
    "        menu_name = name_match.group(1).strip() if name_match else \"ë©”ë‰´ëª… ë¶ˆëª…\"\n",
    "\n",
    "    return {\n",
    "        \"name\": menu_name,\n",
    "        \"price\": price_match.group(0) if price_match else \"ê°€ê²© ì •ë³´ ì—†ìŒ\",\n",
    "        \"description\": description_match.group(1).strip() if description_match else \"ì„¤ëª… ì—†ìŒ\"\n",
    "    }\n",
    "\n",
    "@tool\n",
    "def db_search_cafe_func(query: str) -> str:\n",
    "    \"\"\"\n",
    "    íŠ¹ì • ì¹´í˜ì˜ ë©”ë‰´ ì •ë³´, ê°€ê²©, ë˜ëŠ” ê´€ë ¨ ì„¸ë¶€ ì •ë³´ë¥¼ ì°¾ì„ ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤. \n",
    "    ê²€ìƒ‰ëœ ë¬¸ì„œì—ì„œ í•µì‹¬ ì •ë³´(ì´ë¦„, ê°€ê²©, ì„¤ëª…)ë¥¼ ì¶”ì¶œí•˜ì—¬ ìš”ì•½ëœ JSON ë°°ì—´ í˜•íƒœë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    docs = cafe_db.similarity_search(query, k=4)\n",
    "    \n",
    "    if len(docs) == 0:\n",
    "        return \"ê´€ë ¨ ì¹´í˜ ë©”ë‰´ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "    \n",
    "    # extract_menu_infoë¥¼ ì‚¬ìš©í•˜ì—¬ êµ¬ì¡°í™”ëœ ì •ë³´ë¡œ ë³€í™˜\n",
    "    structured_info = [extract_menu_info(doc) for doc in docs]\n",
    "    \n",
    "    # LLMì—ê²Œ ì „ë‹¬í•  í…ìŠ¤íŠ¸ í˜•íƒœë¡œ ë³€í™˜ (JSON ë¬¸ìì—´ì´ë‚˜ ê°€ë…ì„± ì¢‹ì€ í…ìŠ¤íŠ¸)\n",
    "    context_text = \"ê²€ìƒ‰ëœ ë©”ë‰´ ì •ë³´:\\n\"\n",
    "    for item in structured_info:\n",
    "        context_text += f\"- ë©”ë‰´ëª…: {item['name']}, ê°€ê²©: {item['price']}, ì„¤ëª…: {item['description'][:50]}...\\n\"\n",
    "        \n",
    "    return context_text\n",
    "# LLM ëª¨ë¸ \n",
    "#llm = ChatOpenAI(model=\"gpt-4o-mini\", streaming=True)\n",
    "llm = ChatUpstage(\n",
    "        model=\"solar-pro\",\n",
    "        base_url=\"https://api.upstage.ai/v1\",\n",
    "        temperature=0.5\n",
    ")\n",
    "\n",
    "# ë„êµ¬ ëª©ë¡\n",
    "tools = [db_search_cafe_func]\n",
    "system_prompt = dedent(\"\"\"\n",
    "    ë‹¹ì‹ ì€ ì¹œì ˆí•œ ì¹´í˜ ë©”ë‰´ ì•ˆë‚´ AIì…ë‹ˆë‹¤.\n",
    "    ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ 'db_search_cafe_func'ë¥¼ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸ì— í•„ìš”í•œ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³ ,\n",
    "    ê²€ìƒ‰ëœ **êµ¬ì¡°í™”ëœ ë©”ë‰´ ì •ë³´**ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œêµ­ì–´ë¡œ ì¹œì ˆí•˜ê³  ì •í™•í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.\n",
    "\"\"\")\n",
    "\n",
    "llm_with_tools=llm.bind_tools(tools)\n",
    "class GraphState(MessagesState):\n",
    "    pass\n",
    "\n",
    "def call_model(state: GraphState):\n",
    "    # ì‹œìŠ¤í…œ ë©”ì‹œì§€ë¥¼ ì •ì˜í•˜ì—¬ LLMì˜ í˜ë¥´ì†Œë‚˜ì™€ ì—­í• ì„ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "    system_message = SystemMessage(content=system_prompt)\n",
    "    # ê¸°ì¡´ ë©”ì‹œì§€ ëª©ë¡ ì•ì— ì‹œìŠ¤í…œ ë©”ì‹œì§€ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.\n",
    "    messages = [system_message] + state['messages']\n",
    "    # ë„êµ¬ í˜¸ì¶œ ê¸°ëŠ¥ì´ í™œì„±í™”ëœ LLMì„ í˜¸ì¶œí•˜ì—¬ ì‘ë‹µì„ ë°›ìŠµë‹ˆë‹¤.\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "    # LLMì˜ ì‘ë‹µì„ ìƒíƒœì— ì €ì¥í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def should_continue(state: GraphState):\n",
    "    # ê°€ì¥ ë§ˆì§€ë§‰ ë©”ì‹œì§€ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    \n",
    "    # ë§ˆì§€ë§‰ ë©”ì‹œì§€ì— ë„êµ¬ í˜¸ì¶œì´ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´, \"execute_tools\" ë…¸ë“œë¡œ ì´ë™í•©ë‹ˆë‹¤.\n",
    "    if last_message.tool_calls:\n",
    "        return \"execute_tools\"\n",
    "    # ë„êµ¬ í˜¸ì¶œì´ ì—†ìœ¼ë©´, ëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.\n",
    "    return END\n",
    "\n",
    "\n",
    "builder = StateGraph(GraphState)\n",
    "builder.add_node(\"call_model\", call_model)\n",
    "builder.add_node(\"execute_tools\", ToolNode(tools))\n",
    "\n",
    "builder.add_edge(START, \"call_model\")\n",
    "builder.add_conditional_edges(\n",
    "    \"call_model\",\n",
    "    should_continue,\n",
    "    {\n",
    "        # 'should_continue'ê°€ \"execute_tools\"ë¥¼ ë°˜í™˜í•˜ë©´, í•´ë‹¹ ë…¸ë“œë¡œ ì´ë™í•©ë‹ˆë‹¤.\n",
    "        \"execute_tools\": \"execute_tools\",\n",
    "        # 'should_continue'ê°€ ENDë¥¼ ë°˜í™˜í•˜ë©´, ê·¸ë˜í”„ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.\n",
    "        END: END\n",
    "    }\n",
    ")\n",
    "builder.add_edge(\"execute_tools\", \"call_model\")\n",
    "my_graph = builder.compile()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76f9c232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "\n",
      "ë‹¹ì‹ ì€ ì¹œì ˆí•œ ì¹´í˜ ë©”ë‰´ ì•ˆë‚´ AIì…ë‹ˆë‹¤.\n",
      "ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ 'db_search_cafe_func'ë¥¼ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸ì— í•„ìš”í•œ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³ ,\n",
      "ê²€ìƒ‰ëœ **êµ¬ì¡°í™”ëœ ë©”ë‰´ ì •ë³´**ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œêµ­ì–´ë¡œ ì¹œì ˆí•˜ê³  ì •í™•í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "ì¹´í˜ë¼ë–¼ëŠ” ìˆë‚˜ìš”?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[í•´ë‹¹ ì¹´í˜ì— \"ì¹´í˜ë¼ë–¼\" ë©”ë‰´ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•˜ê¸° ìœ„í•´ í•„ìˆ˜ì ì¸ ê²€ìƒ‰ í•¨ìˆ˜ì…ë‹ˆë‹¤. ë©”ë‰´ ìœ ë¬´ ë° ê°€ê²©/ì„¤ëª… ë“± í•µì‹¬ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì—¬ ì •í™•íˆ ì•ˆë‚´í•˜ê¸° ìœ„í•´ í•„ìš”í•©ë‹ˆë‹¤.]  \n",
      "\n",
      "ê²€ìƒ‰ ê²°ê³¼ë¥¼ í™•ì¸í•œ í›„ ë‹¤ìŒê³¼ ê°™ì´ ë‹µë³€ë“œë¦¬ê² ìŠµë‹ˆë‹¤:  \n",
      "\"ì˜ˆ, ì¹´í˜ë¼ë–¼ëŠ” í˜„ì¬ [ê°€ê²©]ì›ì— íŒë§¤ ì¤‘ì´ë©°, [ì„¤ëª…]ì…ë‹ˆë‹¤. ì£¼ë¬¸ ì‹œ ì°¸ê³ í•´ ì£¼ì„¸ìš”!\"  \n",
      "(ë˜ëŠ” \"ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ì¹´í˜ë¼ë–¼ëŠ” ë©”ë‰´ì— ì—†ëŠ” ê²ƒìœ¼ë¡œ í™•ì¸ë©ë‹ˆë‹¤.\")\n",
      "Tool Calls:\n",
      "  db_search_cafe_func (chatcmpl-tool-88a0fae13b9245e588f3463a2d06ae8b)\n",
      " Call ID: chatcmpl-tool-88a0fae13b9245e588f3463a2d06ae8b\n",
      "  Args:\n",
      "    query: ì¹´í˜ë¼ë–¼\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: db_search_cafe_func\n",
      "\n",
      "ê²€ìƒ‰ëœ ë©”ë‰´ ì •ë³´:\n",
      "- ë©”ë‰´ëª…: ì¹´í˜ë¼ë–¼, ê°€ê²©: â‚©5,500, ì„¤ëª…: ì§„í•œ ì—ìŠ¤í”„ë ˆì†Œì— ë¶€ë“œëŸ½ê²Œ ìŠ¤íŒ€í•œ ìš°ìœ ë¥¼ ë„£ì–´ ë§Œë“  ëŒ€í‘œì ì¸ ë°€í¬ ì»¤í”¼ì…ë‹ˆë‹¤. í¬ë¦¬ë¯¸í•œ ì§ˆ...\n",
      "- ë©”ë‰´ëª…: ë°”ë‹ë¼ ë¼ë–¼, ê°€ê²©: â‚©6,000, ì„¤ëª…: ì¹´í˜ë¼ë–¼ì— ë‹¬ì½¤í•œ ë°”ë‹ë¼ ì‹œëŸ½ì„ ë”í•œ ì¸ê¸° ë©”ë‰´ì…ë‹ˆë‹¤. ë°”ë‹ë¼ì˜ ë‹¬ì½¤í•¨ê³¼ ì»¤í”¼ì˜ ìŒ‰ì‹¸ë¦„í•¨ì´...\n",
      "- ë©”ë‰´ëª…: ì¹´í‘¸ì¹˜ë…¸, ê°€ê²©: â‚©5,000, ì„¤ëª…: ì—ìŠ¤í”„ë ˆì†Œ, ìŠ¤íŒ€ ë°€í¬, ìš°ìœ  ê±°í’ˆì´ 1:1:1 ë¹„ìœ¨ë¡œ êµ¬ì„±ëœ ì´íƒˆë¦¬ì•„ ì „í†µ ì»¤í”¼ì…ë‹ˆë‹¤. ...\n",
      "- ë©”ë‰´ëª…: ì¹´ë¼ë©œ ë§ˆí‚¤ì•„í† , ê°€ê²©: â‚©6,500, ì„¤ëª…: ìŠ¤íŒ€ ë°€í¬ ìœ„ì— ì—ìŠ¤í”„ë ˆì†Œë¥¼ ë¶€ì–´ ë§Œë“  í›„ ì¹´ë¼ë©œ ì‹œëŸ½ê³¼ íœ˜í•‘í¬ë¦¼ìœ¼ë¡œ ë§ˆë¬´ë¦¬í•œ ë‹¬ì½¤í•œ ì»¤í”¼...\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "ë„¤, ì¹´í˜ë¼ë–¼ëŠ” í˜„ì¬ ë©”ë‰´ì— ìˆìŠµë‹ˆë‹¤!  \n",
      "\n",
      "- **ë©”ë‰´ëª…**: ì¹´í˜ë¼ë–¼  \n",
      "- **ê°€ê²©**: â‚©5,500  \n",
      "- **ì„¤ëª…**: ì§„í•œ ì—ìŠ¤í”„ë ˆì†Œì— ë¶€ë“œëŸ½ê²Œ ìŠ¤íŒ€í•œ ìš°ìœ ë¥¼ ë„£ì–´ ë§Œë“  ëŒ€í‘œì ì¸ ë°€í¬ ì»¤í”¼ì…ë‹ˆë‹¤. í¬ë¦¬ë¯¸í•œ ì§ˆê°ê³¼ ê· í˜• ì¡íŒ ë§›ì´ íŠ¹ì§•ì…ë‹ˆë‹¤.  \n",
      "\n",
      "ì¶”ê°€ë¡œ ë°”ë‹ë¼ ë¼ë–¼(â‚©6,000), ì¹´í‘¸ì¹˜ë…¸(â‚©5,000), ì¹´ë¼ë©œ ë§ˆí‚¤ì•„í† (â‚©6,500) ë“±ë„ í•¨ê»˜ í™•ì¸í•´ ë³´ì‹œê¸¸ ì¶”ì²œë“œë¦½ë‹ˆë‹¤ ğŸ˜Š  \n",
      "\n",
      "ì£¼ë¬¸ ì‹œ ì°¸ê³ í•˜ì‹œë©°, ë§›ìˆëŠ” ì»¤í”¼ ë˜ì„¸ìš”! â˜•\n"
     ]
    }
   ],
   "source": [
    "\n",
    "query = \"ì¹´í˜ë¼ë–¼ëŠ” ìˆë‚˜ìš”?\"\n",
    "messages = [\n",
    "        SystemMessage(content=system_prompt),\n",
    "        HumanMessage(content=query)\n",
    "    ]\n",
    "inputs = {\"messages\": messages}\n",
    "# my_graph ë³€ìˆ˜ëŠ” ì§ì ‘ StateGraphë¥¼ ìƒì„±í•˜ê³  ë…¸ë“œì™€ ì—£ì§€ë¥¼ ì¶”ê°€\n",
    "messages = my_graph.invoke(inputs)\n",
    "\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mylangchain-app-SBe-Yh6W-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
