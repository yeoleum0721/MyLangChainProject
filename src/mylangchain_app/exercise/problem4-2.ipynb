{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bd9054f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk\n",
      "Fy\n",
      "tvly\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:2])\n",
    "\n",
    "UPSTAGE_API_KEY = os.getenv(\"UPSTAGE_API_KEY\")\n",
    "print(UPSTAGE_API_KEY[30:])\n",
    "\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
    "print(TAVILY_API_KEY[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0aed0d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "# from langchain_core.tools import tool\n",
    "from langchain.agents import tool\n",
    "from langchain_community.tools import TavilySearchResults\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_upstage import UpstageEmbeddings\n",
    "from langchain_upstage import ChatUpstage\n",
    "\n",
    "# LangGraph MessagesState라는 미리 만들어진 상태를 사용\n",
    "from langgraph.graph import MessagesState\n",
    "from langchain_core.documents import Document\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "from textwrap import dedent\n",
    "from typing import List, Literal, Tuple\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "from pprint import pprint\n",
    "import re\n",
    "\n",
    "import uuid\n",
    "embeddings_model = UpstageEmbeddings(model=\"solar-embedding-1-large\")\n",
    "\n",
    "cafe_db = FAISS.load_local(\n",
    "    \"./db/cafe_db\", \n",
    "    embeddings_model, \n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "\n",
    "def extract_menu_info(doc: Document) -> dict:\n",
    "    \"\"\"Vector DB 문서에서 구조화된 메뉴 정보 추출\"\"\"\n",
    "    content = doc.page_content\n",
    "    # Document의 metadata에 메뉴명이 있는 경우 사용, 없으면 내용에서 추출 시도\n",
    "    menu_name = doc.metadata.get('menu_name', 'Unknown')\n",
    "    \n",
    "    # 정규표현식으로 가격, 설명 등 추출\n",
    "    price_match = re.search(r'₩([\\d,]+)', content)\n",
    "    description_match = re.search(r'설명:\\s*(.+?)(?:\\n|$)', content, re.DOTALL)\n",
    "    \n",
    "    # metadata에 메뉴명이 없을 경우 content에서 \"메뉴:\" 부분을 찾아서 사용\n",
    "    if menu_name == 'Unknown':\n",
    "        name_match = re.search(r'메뉴:\\s*(.+?)(?:,|$)', content)\n",
    "        menu_name = name_match.group(1).strip() if name_match else \"메뉴명 불명\"\n",
    "\n",
    "    return {\n",
    "        \"name\": menu_name,\n",
    "        \"price\": price_match.group(0) if price_match else \"가격 정보 없음\",\n",
    "        \"description\": description_match.group(1).strip() if description_match else \"설명 없음\"\n",
    "    }\n",
    "\n",
    "@tool\n",
    "def db_search_cafe_func(query: str) -> str:\n",
    "    \"\"\"\n",
    "    특정 카페의 메뉴 정보, 가격, 또는 관련 세부 정보를 찾을 때 사용합니다. \n",
    "    검색된 문서에서 핵심 정보(이름, 가격, 설명)를 추출하여 요약된 JSON 배열 형태로 반환합니다.\n",
    "    \"\"\"\n",
    "    docs = cafe_db.similarity_search(query, k=4)\n",
    "    \n",
    "    if len(docs) == 0:\n",
    "        return \"관련 카페 메뉴 정보를 찾을 수 없습니다.\"\n",
    "    \n",
    "    # extract_menu_info를 사용하여 구조화된 정보로 변환\n",
    "    structured_info = [extract_menu_info(doc) for doc in docs]\n",
    "    \n",
    "    # LLM에게 전달할 텍스트 형태로 변환 (JSON 문자열이나 가독성 좋은 텍스트)\n",
    "    context_text = \"검색된 메뉴 정보:\\n\"\n",
    "    for item in structured_info:\n",
    "        context_text += f\"- 메뉴명: {item['name']}, 가격: {item['price']}, 설명: {item['description'][:50]}...\\n\"\n",
    "        \n",
    "    return context_text\n",
    "# LLM 모델 \n",
    "#llm = ChatOpenAI(model=\"gpt-4o-mini\", streaming=True)\n",
    "llm = ChatUpstage(\n",
    "        model=\"solar-pro\",\n",
    "        base_url=\"https://api.upstage.ai/v1\",\n",
    "        temperature=0.5\n",
    ")\n",
    "\n",
    "# 도구 목록\n",
    "tools = [db_search_cafe_func]\n",
    "system_prompt = dedent(\"\"\"\n",
    "    당신은 친절한 카페 메뉴 안내 AI입니다.\n",
    "    사용 가능한 도구 'db_search_cafe_func'를 사용하여 질문에 필요한 정보를 검색하고,\n",
    "    검색된 **구조화된 메뉴 정보**를 바탕으로 한국어로 친절하고 정확하게 답변하세요.\n",
    "\"\"\")\n",
    "\n",
    "llm_with_tools=llm.bind_tools(tools)\n",
    "class GraphState(MessagesState):\n",
    "    pass\n",
    "\n",
    "def call_model(state: GraphState):\n",
    "    # 시스템 메시지를 정의하여 LLM의 페르소나와 역할을 설정합니다.\n",
    "    system_message = SystemMessage(content=system_prompt)\n",
    "    # 기존 메시지 목록 앞에 시스템 메시지를 추가합니다.\n",
    "    messages = [system_message] + state['messages']\n",
    "    # 도구 호출 기능이 활성화된 LLM을 호출하여 응답을 받습니다.\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "    # LLM의 응답을 상태에 저장하여 반환합니다.\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def should_continue(state: GraphState):\n",
    "    # 가장 마지막 메시지를 가져옵니다.\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    \n",
    "    # 마지막 메시지에 도구 호출이 포함되어 있으면, \"execute_tools\" 노드로 이동합니다.\n",
    "    if last_message.tool_calls:\n",
    "        return \"execute_tools\"\n",
    "    # 도구 호출이 없으면, 대화를 종료합니다.\n",
    "    return END\n",
    "\n",
    "\n",
    "builder = StateGraph(GraphState)\n",
    "builder.add_node(\"call_model\", call_model)\n",
    "builder.add_node(\"execute_tools\", ToolNode(tools))\n",
    "\n",
    "builder.add_edge(START, \"call_model\")\n",
    "builder.add_conditional_edges(\n",
    "    \"call_model\",\n",
    "    should_continue,\n",
    "    {\n",
    "        # 'should_continue'가 \"execute_tools\"를 반환하면, 해당 노드로 이동합니다.\n",
    "        \"execute_tools\": \"execute_tools\",\n",
    "        # 'should_continue'가 END를 반환하면, 그래프를 종료합니다.\n",
    "        END: END\n",
    "    }\n",
    ")\n",
    "builder.add_edge(\"execute_tools\", \"call_model\")\n",
    "my_graph = builder.compile()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76f9c232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "\n",
      "당신은 친절한 카페 메뉴 안내 AI입니다.\n",
      "사용 가능한 도구 'db_search_cafe_func'를 사용하여 질문에 필요한 정보를 검색하고,\n",
      "검색된 **구조화된 메뉴 정보**를 바탕으로 한국어로 친절하고 정확하게 답변하세요.\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "카페라떼는 있나요?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[해당 카페에 \"카페라떼\" 메뉴가 존재하는지 확인하기 위해 필수적인 검색 함수입니다. 메뉴 유무 및 가격/설명 등 핵심 정보를 추출하여 정확히 안내하기 위해 필요합니다.]  \n",
      "\n",
      "검색 결과를 확인한 후 다음과 같이 답변드리겠습니다:  \n",
      "\"예, 카페라떼는 현재 [가격]원에 판매 중이며, [설명]입니다. 주문 시 참고해 주세요!\"  \n",
      "(또는 \"죄송합니다. 현재 카페라떼는 메뉴에 없는 것으로 확인됩니다.\")\n",
      "Tool Calls:\n",
      "  db_search_cafe_func (chatcmpl-tool-88a0fae13b9245e588f3463a2d06ae8b)\n",
      " Call ID: chatcmpl-tool-88a0fae13b9245e588f3463a2d06ae8b\n",
      "  Args:\n",
      "    query: 카페라떼\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: db_search_cafe_func\n",
      "\n",
      "검색된 메뉴 정보:\n",
      "- 메뉴명: 카페라떼, 가격: ₩5,500, 설명: 진한 에스프레소에 부드럽게 스팀한 우유를 넣어 만든 대표적인 밀크 커피입니다. 크리미한 질...\n",
      "- 메뉴명: 바닐라 라떼, 가격: ₩6,000, 설명: 카페라떼에 달콤한 바닐라 시럽을 더한 인기 메뉴입니다. 바닐라의 달콤함과 커피의 쌉싸름함이...\n",
      "- 메뉴명: 카푸치노, 가격: ₩5,000, 설명: 에스프레소, 스팀 밀크, 우유 거품이 1:1:1 비율로 구성된 이탈리아 전통 커피입니다. ...\n",
      "- 메뉴명: 카라멜 마키아토, 가격: ₩6,500, 설명: 스팀 밀크 위에 에스프레소를 부어 만든 후 카라멜 시럽과 휘핑크림으로 마무리한 달콤한 커피...\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "네, 카페라떼는 현재 메뉴에 있습니다!  \n",
      "\n",
      "- **메뉴명**: 카페라떼  \n",
      "- **가격**: ₩5,500  \n",
      "- **설명**: 진한 에스프레소에 부드럽게 스팀한 우유를 넣어 만든 대표적인 밀크 커피입니다. 크리미한 질감과 균형 잡힌 맛이 특징입니다.  \n",
      "\n",
      "추가로 바닐라 라떼(₩6,000), 카푸치노(₩5,000), 카라멜 마키아토(₩6,500) 등도 함께 확인해 보시길 추천드립니다 😊  \n",
      "\n",
      "주문 시 참고하시며, 맛있는 커피 되세요! ☕\n"
     ]
    }
   ],
   "source": [
    "\n",
    "query = \"카페라떼는 있나요?\"\n",
    "messages = [\n",
    "        SystemMessage(content=system_prompt),\n",
    "        HumanMessage(content=query)\n",
    "    ]\n",
    "inputs = {\"messages\": messages}\n",
    "# my_graph 변수는 직접 StateGraph를 생성하고 노드와 엣지를 추가\n",
    "messages = my_graph.invoke(inputs)\n",
    "\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mylangchain-app-SBe-Yh6W-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
