{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2102ef55",
   "metadata": {},
   "source": [
    "### API Key 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76623c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gsk_G\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# .env 파일을 불러와서 환경 변수로 설정\n",
    "load_dotenv(dotenv_path='.env')\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b88be7",
   "metadata": {},
   "source": [
    "### 문제 1-1 기본 Chain 만들기 - AI 요리사\n",
    "\n",
    "- 문제 설명 :\n",
    "사용자가 재료를 입력하면 그 재료로 만들 수 있는 요리를 추천해주는 간단한 AI 요리사를 만들어보세요.\n",
    "\n",
    "요구사항\n",
    "1. PromptTemplate을 사용하여 프롬프트 작성\n",
    "2. 사용자가 입력한 재료를 받아서 만들 수 있는 요리 추천\n",
    "3. ChatOpenAI 모델 사용\n",
    "4. StrOutputParser로 결과를 문자열로 출력\n",
    "5. LCEL(|) 문법을 사용하여 체인 연결\n",
    "\n",
    "- 구현 조건 : \n",
    "입력: 재료명 (예: \"토마토, 양파, 치즈\")\n",
    "출력: 추천 요리와 간단한 레시피\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d27ad0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "토마토, 양파, 치즈를 이용한 추천요리인 '토마토, 양파 치즈 오믈렛'에 대해서 알려드리겠습니다.\n",
      "\n",
      "**재료**\n",
      "\n",
      "*   토마토 1개\n",
      "*   양파 1/2개\n",
      "*   치즈 1판\n",
      "*   계란 2개\n",
      "*   소금, 후추 \n",
      "\n",
      "**레시피**\n",
      "\n",
      "1.  양파를 깨끗이 씻은 후 채썰기를 합니다.\n",
      "2.  토마토를 깨끗이 씻은 후, 네모로 썰어줍니다.\n",
      "3.  계란을 깨어 소금과 후추로 간을 한 후, 잘 섞어줍니다.\n",
      "4.  달군 프라이팬에 기름을 두르고, 양파와 토마토를 볶다가 토마토가 살짝 물러지면 접시에 덜어둡니다.\n",
      "5.  같은 프라이팬에 기름을 두르고 계란물을 넣고 약불로 만들어서 계란이 반쯤 익으면, 볶아둔 토마토와 양파를 넣고, 치즈를 올립니다.\n",
      "6.  팬의 가장자리가 익으면, 오믈렛을 반으로 접습니다.\n",
      "7.  맛있는 '토마토, 양파 치즈 오믈렛'이 완성되었습니다."
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 1. 컴포넌트 정의\n",
    "prompt = PromptTemplate.from_template(\"당신은 요리사입니다.  <Question>: {input}를 이용한 추천요리와 간단한 레시피를 알려주세요\")\n",
    "\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# chain 연결 (LCEL)\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# 스트리밍 출력을 위한 요청\n",
    "answer = chain.stream({\"input\": \"토마토, 양파, 치즈\"})\n",
    "# 스트리밍 출력\n",
    "#print(answer)\n",
    "\n",
    "for token in answer:\n",
    "    # 스트림에서 받은 데이터의 내용을 출력합니다. 줄바꿈 없이 이어서 출력하고, 버퍼를 즉시 비웁니다.\n",
    "    print(token, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384df77b",
   "metadata": {},
   "source": [
    "### 문제 1-2 Multi Chain 만들기 - 여행지 정보 시스템\n",
    "- 문제 설명 :\n",
    "    사용자가 특정 도시나 국가를 입력하면, 해당 지역의 대표적인 관광 명소를 추천하고 그 명소에 대한 상세 정보(역사, 특징, 방문 팁 등)를 알려주는 2단계 체인을 구현해 보세요.\n",
    "- 요구사항\n",
    "1. 1단계 체인: 여행지(도시/국가)를 입력받아 대표 명소 1가지 추천\n",
    "2. 2단계 체인: 추천받은 명소의 상세 정보 제공\n",
    "3. ChatPromptTemplate 사용 \n",
    ": “system”  과 “user” 메시지를 지정합니다.\n",
    "4. 두 체인을 LCEL로 연결\n",
    "5. 각 단계의 결과를 모두 출력하여 과정 확인\n",
    "- 구현 조건\n",
    "    - 입력: 여행지 (예: \"로마\", \"뉴욕\", \"도쿄\")\n",
    "    - 1단계 출력: 추천 명소 이름\n",
    "    - 2단계 출력: 명소에 대한 상세 정보 (역사, 특징, 방문 팁 등)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0fd1818",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'OPENAI_API_KEY' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m      8\u001b[39m prompt1 = ChatPromptTemplate.from_messages(\n\u001b[32m      9\u001b[39m     [ (\u001b[33m\"\u001b[39m\u001b[33msystem\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m당신은 여행유튜버입니다.\u001b[39m\u001b[33m\"\u001b[39m) , \n\u001b[32m     10\u001b[39m      (\u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[38;5;132;01m{place}\u001b[39;00m\u001b[33m 에서 대표명소 한 곳을 추천해주세요\u001b[39m\u001b[33m\"\u001b[39m) ]\n\u001b[32m     11\u001b[39m )\n\u001b[32m     12\u001b[39m prompt2 = ChatPromptTemplate.from_messages(\n\u001b[32m     13\u001b[39m     [ (\u001b[33m\"\u001b[39m\u001b[33msystem\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m당신은 여행유튜버입니다.\u001b[39m\u001b[33m\"\u001b[39m) , \n\u001b[32m     14\u001b[39m      (\u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[38;5;132;01m{landmark}\u001b[39;00m\u001b[33m가 어딘지 알려주고 이 곳에 대한 상세정보를 알려주세요\u001b[39m\u001b[33m\"\u001b[39m) ]\n\u001b[32m     15\u001b[39m )\n\u001b[32m     17\u001b[39m llm = ChatOpenAI(\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m     api_key=\u001b[43mOPENAI_API_KEY\u001b[49m,\n\u001b[32m     19\u001b[39m     base_url=\u001b[33m\"\u001b[39m\u001b[33mhttps://api.groq.com/openai/v1\u001b[39m\u001b[33m\"\u001b[39m, \n\u001b[32m     20\u001b[39m     model=\u001b[33m\"\u001b[39m\u001b[33mmoonshotai/kimi-k2-instruct-0905\u001b[39m\u001b[33m\"\u001b[39m, \n\u001b[32m     21\u001b[39m     temperature=\u001b[32m0.7\u001b[39m\n\u001b[32m     22\u001b[39m )\n\u001b[32m     24\u001b[39m chain1 = prompt1 | llm | StrOutputParser()\n\u001b[32m     26\u001b[39m chain2 = (\n\u001b[32m     27\u001b[39m     {\u001b[33m\"\u001b[39m\u001b[33mlandmark\u001b[39m\u001b[33m\"\u001b[39m: chain1}  \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m     28\u001b[39m     | prompt2\n\u001b[32m     29\u001b[39m     | llm\n\u001b[32m     30\u001b[39m     | StrOutputParser()\n\u001b[32m     31\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'OPENAI_API_KEY' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "prompt1 = ChatPromptTemplate.from_messages(\n",
    "    [ (\"system\", \"당신은 여행유튜버입니다.\") , \n",
    "     (\"user\", \"{place} 에서 대표명소 한 곳을 추천해주세요\") ]\n",
    ")\n",
    "prompt2 = ChatPromptTemplate.from_messages(\n",
    "    [ (\"system\", \"당신은 여행유튜버입니다.\") , \n",
    "     (\"user\", \"{landmark}가 어딘지 알려주고 이 곳에 대한 상세정보를 알려주세요\") ]\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\", \n",
    "    model=\"moonshotai/kimi-k2-instruct-0905\", \n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "chain1 = prompt1 | llm | StrOutputParser()\n",
    "\n",
    "chain2 = (\n",
    "    {\"landmark\": chain1}  #\n",
    "    | prompt2\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "response = chain2.invoke({\"place\": \"프랑스\"})\n",
    "print(\"\\n🔹 명소 소개:\")\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58548a44",
   "metadata": {},
   "source": [
    "### 문제1-3  FewShotPromptTemplate과 시스템 메시지 활용 \n",
    "\n",
    "- 뉴스 키워드 추출기\n",
    "1) 문제 설명\n",
    "    - FewShotPromptTemplate을 사용하여 뉴스 기사에서 핵심 키워드 3개를 추출하는 시스템을 구현해보세요. 주어진 예시들을 참고하여 일관된 형식으로 키워드를 추출해야 합니다.\n",
    "2) 요구사항\n",
    "    - FewShotPromptTemplate 사용\n",
    "    - 최소 3개의 예시(examples) 포함\n",
    "    - 뉴스 텍스트에서 핵심 키워드 3개 추출\n",
    "    - 일관된 출력 형식 유지\n",
    "    - 다양한 분야의 뉴스로 테스트\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee10bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first=ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='뉴스 키워드 추출 전문가입니다. 핵심 키워드 3개를 추출하세요.'), additional_kwargs={}), FewShotChatMessagePromptTemplate(examples=[{'news': '삼성전자가 내년 초에 자체적으로 개발한 인공지능(AI) 가속기를 처음으로 출시할 예정이다. 이는 AI 반도체 시장에서 지배적인 위치를 차지하고 있는 엔비디아의 독점을 도전하고, 세계 최고의 반도체 제조업체로서의 지위를 다시 확립하려는 삼성전자의 노력으로 해석된다.', 'keywords': '삼성전자, 인공지능, 엔비디아'}, {'news': '세계보건기구(WHO)는 최근 새로운 건강 위기에 대응하기 위해 국제 협력의 중요성을 강조했다. 전염병 대응 역량의 강화와 글로벌 보건 시스템의 개선이 필요하다고 발표했다.', 'keywords': '세계보건기구, 건강위기, 국제협력'}], input_variables=[], input_types={}, partial_variables={}, example_prompt=ChatPromptTemplate(input_variables=['keywords', 'news'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['news'], input_types={}, partial_variables={}, template='{news}'), additional_kwargs={}), AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=['keywords'], input_types={}, partial_variables={}, template='키워드: {keywords}'), additional_kwargs={})])), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})]) middle=[] last=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000001D838E248C0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001D8393097F0>, root_client=<openai.OpenAI object at 0x000001D838E22D80>, root_async_client=<openai.AsyncOpenAI object at 0x000001D838E24A10>, model_name='meta-llama/llama-4-scout-17b-16e-instruct', temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://api.groq.com/openai/v1')\n",
      "키워드: 제미나이, 구글, AI모델\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import (\n",
    "    FewShotChatMessagePromptTemplate, \n",
    "    ChatPromptTemplate\n",
    ")\n",
    "\n",
    "# 1. 예시 프롬프트 (대화형)\n",
    "example_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"{news}\"),\n",
    "    (\"ai\", \"키워드: {keywords}\")\n",
    "])\n",
    "\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"news\": \"삼성전자가 내년 초에 자체적으로 개발한 인공지능(AI) 가속기를 처음으로 출시할 예정이다.\\\n",
    "        이는 AI 반도체 시장에서 지배적인 위치를 차지하고 있는 엔비디아의 독점을 도전하고, 세계 최고의 반도체 제조업체로서의 지위를 다시 확립하려는 삼성전자의 노력으로 해석된다.\",\n",
    "        \"keywords\": \"삼성전자, 인공지능, 엔비디아\"\n",
    "    },\n",
    "    {\n",
    "        \"news\": \"세계보건기구(WHO)는 최근 새로운 건강 위기에 대응하기 위해 국제 협력의 중요성을 강조했다. \\\n",
    "        전염병 대응 역량의 강화와 글로벌 보건 시스템의 개선이 필요하다고 발표했다.\",\n",
    "        \"keywords\": \"세계보건기구, 건강위기, 국제협력\"\n",
    "    },\n",
    "    # 추가 예시 필요\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# 2. Few-Shot 프롬프트\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples\n",
    ")\n",
    "\n",
    "# 3. 최종 프롬프트\n",
    "final_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"뉴스 키워드 추출 전문가입니다. 핵심 키워드 3개를 추출하세요.\"),\n",
    "    few_shot_prompt,\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "# 모델 생성 및 체인 구성\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.0)\n",
    "chain = final_prompt | llm\n",
    "print(chain)\n",
    "\n",
    "# 테스트 실행\n",
    "result = chain.invoke({\"input\":\"제미나이 2.0 플래시는 현재 구글 AI 스튜디오(Google AI Studio) 및 \\\n",
    "                       버텍스 AI(Vertex AI)에서 제미나이 API를 통해 개발자에게 실험 모델로 제공됩니다. 모든 개발자는 멀티모달 입력 및 텍스트 출력을 사용할 수 있으며,\\\n",
    "                        텍스트 음성 변환(text-to-speech) 및 네이티브 이미지 생성은 일부 파트너들을 대상으로 제공됩니다. 내년 1월에는 더 많은 모델 사이즈와 함께 일반에 공개될 예정입니다.\"})\n",
    "print(result.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mylangchain-app-SBe-Yh6W-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
