{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. LangChainì—ì„œ ë„êµ¬(tool) í™œìš© ë°©ë²•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk\n",
      "Fy\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# .env íŒŒì¼ì„ ë¶ˆëŸ¬ì™€ì„œ í™˜ê²½ ë³€ìˆ˜ë¡œ ì„¤ì •\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:2])\n",
    "\n",
    "UPSTAGE_API_KEY = os.getenv(\"UPSTAGE_API_KEY\")\n",
    "print(UPSTAGE_API_KEY[30:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\mylangchain-app-SBe-Yh6W-py3.12\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x000001255A1CB2C0> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001255A1F5700> model_name='solar-pro' temperature=0.5 model_kwargs={} upstage_api_key=SecretStr('**********') upstage_api_base='https://api.upstage.ai/v1'\n"
     ]
    }
   ],
   "source": [
    "# from langchain_openai import ChatOpenAI\n",
    "\n",
    "# llm = ChatOpenAI(\n",
    "#     base_url=\"https://api.groq.com/openai/v1\",\n",
    "#     #model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "#     model=\"moonshotai/kimi-k2-instruct-0905\",\n",
    "#     temperature=0\n",
    "# )\n",
    "\n",
    "from langchain_upstage import ChatUpstage\n",
    "llm = ChatUpstage(\n",
    "        model=\"solar-pro\",\n",
    "        base_url=\"https://api.upstage.ai/v1\",\n",
    "        temperature=0.5\n",
    "    )\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [tool decorator](https://python.langchain.com/docs/how_to/custom_tools/#tool-decorator)ë¥¼ ì‚¬ìš©í•˜ë©´ ì‰½ê²Œ ë„êµ¬ë¥¼ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"ìˆ«ì aì™€ bë¥¼ ë”í•©ë‹ˆë‹¤.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"ìˆ«ì aì™€ bë¥¼ ê³±í•©ë‹ˆë‹¤.\"\"\"\n",
    "    return a * b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LLMì„ í˜¸ì¶œí–ˆì„ ë•Œì™€ ë„êµ¬ë¥¼ ì‚¬ìš©í–ˆì„ ë•Œì˜ ì°¨ì´ë¥¼ ì•Œì•„ë´…ë‹ˆë‹¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 ê³±í•˜ê¸° 5ëŠ” **15**ì…ë‹ˆë‹¤.  \n",
      "\n",
      "ê³„ì‚° ê³¼ì •:  \n",
      "3 Ã— 5 = 15  \n",
      "\n",
      "ê°„ë‹¨íˆ ì„¤ëª…í•˜ë©´, 3ì„ 5ë²ˆ ë”í•œ ê²ƒê³¼ ê°™ìŠµë‹ˆë‹¤.  \n",
      "(3 + 3 + 3 + 3 + 3 = 15)  \n",
      "\n",
      "ë„ì›€ì´ ë˜ì—ˆê¸°ë¥¼ ë°”ëë‹ˆë‹¤! ğŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "query = '3 ê³±í•˜ê¸° 5ëŠ”?'\n",
    "llm_result = llm.invoke(query)\n",
    "\n",
    "print(llm_result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ë„êµ¬ ë¦¬ìŠ¤íŠ¸ëŠ” LLMì— í•´ë‹¹í•˜ëŠ” `BaseModel` í´ë˜ìŠ¤ì— `bind_tools` ë©”ì„œë“œë¥¼ í†µí•´ ì „ë‹¬í•©ë‹ˆë‹¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableBinding'>\n",
      "bound=ChatUpstage(client=<openai.resources.chat.completions.completions.Completions object at 0x00000142DE786D50>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x00000142DE795940>, model_name='solar-pro', temperature=0.5, model_kwargs={}, upstage_api_key=SecretStr('**********'), upstage_api_base='https://api.upstage.ai/v1') kwargs={'tools': [{'type': 'function', 'function': {'name': 'add', 'description': 'ìˆ«ì aì™€ bë¥¼ ë”í•©ë‹ˆë‹¤.', 'parameters': {'properties': {'a': {'type': 'integer'}, 'b': {'type': 'integer'}}, 'required': ['a', 'b'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'multiply', 'description': 'ìˆ«ì aì™€ bë¥¼ ê³±í•©ë‹ˆë‹¤.', 'parameters': {'properties': {'a': {'type': 'integer'}, 'b': {'type': 'integer'}}, 'required': ['a', 'b'], 'type': 'object'}}}]} config={} config_factories=[]\n"
     ]
    }
   ],
   "source": [
    "llm_with_tools = llm.bind_tools([add, multiply])\n",
    "\n",
    "print(type(llm_with_tools))\n",
    "print(llm_with_tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `AIMessage`ì˜ `additional_kwargs` ì†ì„±ì€ `tool_calls`ë¥¼ í¬í•¨í•©ë‹ˆë‹¤\n",
    "- `tool_calls`ëŠ” ë„êµ¬ë¥¼ í˜¸ì¶œí•˜ëŠ” ë©”ì‹œì§€ë¥¼ í¬í•¨í•©ë‹ˆë‹¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='[The question directly asks for the product of 3 and 5, which is ESSENTIAL to answer using the `multiply` function. No other operations or functions are necessary.]  \\n\\nResult: 15', additional_kwargs={'tool_calls': [{'id': 'chatcmpl-tool-a9a7ac780be9491499d39eef7aa88752', 'function': {'arguments': '{\"a\": 3, \"b\": 5}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 66, 'prompt_tokens': 578, 'total_tokens': 644, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'solar-pro2-250909', 'system_fingerprint': None, 'id': '14ee0f64-1c8b-4060-b6de-338c3723d48c', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--ee7a8701-7b15-4977-a3c0-958ce6d8aa75-0', tool_calls=[{'name': 'multiply', 'args': {'a': 3, 'b': 5}, 'id': 'chatcmpl-tool-a9a7ac780be9491499d39eef7aa88752', 'type': 'tool_call'}], usage_metadata={'input_tokens': 578, 'output_tokens': 66, 'total_tokens': 644, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_result = llm_with_tools.invoke(query)\n",
    "\n",
    "tool_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'multiply',\n",
       "  'args': {'a': 3, 'b': 5},\n",
       "  'id': 'chatcmpl-tool-a9a7ac780be9491499d39eef7aa88752',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_result.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence\n",
    "\n",
    "from langchain_core.messages import AnyMessage, HumanMessage\n",
    "\n",
    "human_message = HumanMessage(query)\n",
    "message_list: Sequence[AnyMessage] = [human_message] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `tool_calls` ì†ì„±ì€ ë„êµ¬ë¥¼ í˜¸ì¶œí•˜ëŠ” ë©”ì‹œì§€ë¥¼ í¬í•¨í•©ë‹ˆë‹¤\n",
    "- `tool_calls`ë¥¼ ê°€ì§„ `AIMessage`ì˜ í˜•íƒœë¥¼ ê¸°ì–µí•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='[ì£¼ì–´ì§„ ì§ˆë¬¸ì€ \"3 ê³±í•˜ê¸° 5\"ì˜ ê²°ê³¼ë¥¼ ë¬»ëŠ” ê²ƒìœ¼ë¡œ, ì´ëŠ” ì§ì ‘ì ìœ¼ë¡œ ê³±ì…ˆ ì—°ì‚°ì´ í•„ìš”í•©ë‹ˆë‹¤. ë”°ë¼ì„œ \\'multiply\\' í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ëŠ” ê²ƒì´ í•„ìˆ˜ì ì…ë‹ˆë‹¤. ë‹¤ë¥¸ ë°©ë²•ìœ¼ë¡œëŠ” ì¼ë°˜ ì§€ì‹ìœ¼ë¡œë„ ë‹µí•  ìˆ˜ ìˆì§€ë§Œ, ê·œì¹™ì— ë”°ë¼ í•¨ìˆ˜ ì‚¬ìš©ì´ í•„ìš”í•œ ê²½ìš°ì—ë§Œ í˜¸ì¶œí•´ì•¼ í•˜ë©°, ì´ ê²½ìš° ê³±ì…ˆ ì—°ì‚°ì´ ì§ˆë¬¸ì˜ í•µì‹¬ì´ë¯€ë¡œ í•¨ìˆ˜ í˜¸ì¶œì´ ì •ë‹¹í•©ë‹ˆë‹¤.] \\n\\nì •ë‹µ: 15', additional_kwargs={'tool_calls': [{'id': 'chatcmpl-tool-638066a86a0143c682396fe4fde379e5', 'function': {'arguments': '{\"a\": 3, \"b\": 5}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 89, 'prompt_tokens': 578, 'total_tokens': 667, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'solar-pro2-250909', 'system_fingerprint': None, 'id': '11c36d9a-83e6-406f-b0a9-0ee6e9525b33', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--1e6c9b67-caf5-4549-aac5-abddf1b12069-0', tool_calls=[{'name': 'multiply', 'args': {'a': 3, 'b': 5}, 'id': 'chatcmpl-tool-638066a86a0143c682396fe4fde379e5', 'type': 'tool_call'}], usage_metadata={'input_tokens': 578, 'output_tokens': 89, 'total_tokens': 667, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_message = llm_with_tools.invoke(message_list)\n",
    "ai_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'multiply',\n",
       "  'args': {'a': 3, 'b': 5},\n",
       "  'id': 'chatcmpl-tool-638066a86a0143c682396fe4fde379e5',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_message.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='3 ê³±í•˜ê¸° 5ëŠ”?', additional_kwargs={}, response_metadata={}),\n",
      " AIMessage(content='[ì£¼ì–´ì§„ ì§ˆë¬¸ì€ \"3 ê³±í•˜ê¸° 5\"ì˜ ê²°ê³¼ë¥¼ ë¬»ëŠ” ê²ƒìœ¼ë¡œ, ì´ëŠ” ì§ì ‘ì ìœ¼ë¡œ ê³±ì…ˆ ì—°ì‚°ì´ í•„ìš”í•©ë‹ˆë‹¤. ë”°ë¼ì„œ \\'multiply\\' í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ëŠ” ê²ƒì´ í•„ìˆ˜ì ì…ë‹ˆë‹¤. ë‹¤ë¥¸ ë°©ë²•ìœ¼ë¡œëŠ” ì¼ë°˜ ì§€ì‹ìœ¼ë¡œë„ ë‹µí•  ìˆ˜ ìˆì§€ë§Œ, ê·œì¹™ì— ë”°ë¼ í•¨ìˆ˜ ì‚¬ìš©ì´ í•„ìš”í•œ ê²½ìš°ì—ë§Œ í˜¸ì¶œí•´ì•¼ í•˜ë©°, ì´ ê²½ìš° ê³±ì…ˆ ì—°ì‚°ì´ ì§ˆë¬¸ì˜ í•µì‹¬ì´ë¯€ë¡œ í•¨ìˆ˜ í˜¸ì¶œì´ ì •ë‹¹í•©ë‹ˆë‹¤.] \\n\\nì •ë‹µ: 15', additional_kwargs={'tool_calls': [{'id': 'chatcmpl-tool-638066a86a0143c682396fe4fde379e5', 'function': {'arguments': '{\"a\": 3, \"b\": 5}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 89, 'prompt_tokens': 578, 'total_tokens': 667, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'solar-pro2-250909', 'system_fingerprint': None, 'id': '11c36d9a-83e6-406f-b0a9-0ee6e9525b33', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--1e6c9b67-caf5-4549-aac5-abddf1b12069-0', tool_calls=[{'name': 'multiply', 'args': {'a': 3, 'b': 5}, 'id': 'chatcmpl-tool-638066a86a0143c682396fe4fde379e5', 'type': 'tool_call'}], usage_metadata={'input_tokens': 578, 'output_tokens': 89, 'total_tokens': 667, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "message_list.append(ai_message)\n",
    "\n",
    "pprint(message_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `AIMessage`ì˜ `tool_calls`ë¥¼ í™œìš©í•´ì„œ ë„êµ¬ë¥¼ ì§ì ‘ í˜¸ì¶œí•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'multiply',\n",
       " 'args': {'a': 3, 'b': 5},\n",
       " 'id': 'chatcmpl-tool-638066a86a0143c682396fe4fde379e5',\n",
       " 'type': 'tool_call'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_message.tool_calls[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='15' name='multiply' tool_call_id='chatcmpl-tool-638066a86a0143c682396fe4fde379e5'\n"
     ]
    }
   ],
   "source": [
    "tool_message = multiply.invoke(ai_message.tool_calls[0])\n",
    "\n",
    "print(tool_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- í•˜ì§€ë§Œ ì—ì´ì „íŠ¸ì˜ ê²½ìš° ë„êµ¬ë¥¼ ì§ì ‘ í˜¸ì¶œí•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ë„êµ¬ë¥¼ í˜¸ì¶œí•˜ëŠ” ë©”ì‹œì§€ë¥¼ ë§Œë“¤ì–´ì„œ ì „ë‹¬í•©ë‹ˆë‹¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='3 ê³±í•˜ê¸° 5ëŠ”?', additional_kwargs={}, response_metadata={}),\n",
      " AIMessage(content='[ì£¼ì–´ì§„ ì§ˆë¬¸ì€ \"3 ê³±í•˜ê¸° 5\"ì˜ ê²°ê³¼ë¥¼ ë¬»ëŠ” ê²ƒìœ¼ë¡œ, ì´ëŠ” ì§ì ‘ì ìœ¼ë¡œ ê³±ì…ˆ ì—°ì‚°ì´ í•„ìš”í•©ë‹ˆë‹¤. ë”°ë¼ì„œ \\'multiply\\' í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ëŠ” ê²ƒì´ í•„ìˆ˜ì ì…ë‹ˆë‹¤. ë‹¤ë¥¸ ë°©ë²•ìœ¼ë¡œëŠ” ì¼ë°˜ ì§€ì‹ìœ¼ë¡œë„ ë‹µí•  ìˆ˜ ìˆì§€ë§Œ, ê·œì¹™ì— ë”°ë¼ í•¨ìˆ˜ ì‚¬ìš©ì´ í•„ìš”í•œ ê²½ìš°ì—ë§Œ í˜¸ì¶œí•´ì•¼ í•˜ë©°, ì´ ê²½ìš° ê³±ì…ˆ ì—°ì‚°ì´ ì§ˆë¬¸ì˜ í•µì‹¬ì´ë¯€ë¡œ í•¨ìˆ˜ í˜¸ì¶œì´ ì •ë‹¹í•©ë‹ˆë‹¤.] \\n\\nì •ë‹µ: 15', additional_kwargs={'tool_calls': [{'id': 'chatcmpl-tool-638066a86a0143c682396fe4fde379e5', 'function': {'arguments': '{\"a\": 3, \"b\": 5}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 89, 'prompt_tokens': 578, 'total_tokens': 667, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'solar-pro2-250909', 'system_fingerprint': None, 'id': '11c36d9a-83e6-406f-b0a9-0ee6e9525b33', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--1e6c9b67-caf5-4549-aac5-abddf1b12069-0', tool_calls=[{'name': 'multiply', 'args': {'a': 3, 'b': 5}, 'id': 'chatcmpl-tool-638066a86a0143c682396fe4fde379e5', 'type': 'tool_call'}], usage_metadata={'input_tokens': 578, 'output_tokens': 89, 'total_tokens': 667, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      " ToolMessage(content='15', name='multiply', tool_call_id='chatcmpl-tool-638066a86a0143c682396fe4fde379e5')]\n"
     ]
    }
   ],
   "source": [
    "message_list.append(tool_message)\n",
    "\n",
    "pprint(message_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIMessage(content='3 ê³±í•˜ê¸° 5ëŠ” 15ì…ë‹ˆë‹¤. \\n\\ní•¨ìˆ˜ í˜¸ì¶œ ê²°ê³¼ì™€ ì¼ì¹˜í•˜ëŠ” ì •ë‹µì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤.\\n\\n[ì§ˆë¬¸ì˜ í•µì‹¬ì¸ \"3 ê³±í•˜ê¸° 5\" ì—°ì‚°ì„ ìˆ˜í–‰í•˜ê¸° ìœ„í•´ \\'multiply\\' í•¨ìˆ˜ê°€ í•„ìˆ˜ì ìœ¼ë¡œ ìš”êµ¬ë©ë‹ˆë‹¤. ì¼ë°˜ ì§€ì‹ìœ¼ë¡œë„ ë‹µë³€ ê°€ëŠ¥í•˜ì§€ë§Œ, ë¬¸ì œ í•´ê²°ì„ ìœ„í•´ í•¨ìˆ˜ ì‚¬ìš©ì´ ëª…ì‹œì ìœ¼ë¡œ ìš”ì²­ëœ ìƒí™©ìœ¼ë¡œ íŒë‹¨ë©ë‹ˆë‹¤.] \\n\\nìµœì¢… ë‹µë³€: 15', additional_kwargs={'tool_calls': [{'id': 'chatcmpl-tool-99c188eebb814a838f6526d0c3606084', 'function': {'arguments': '{\"a\": 3, \"b\": 5}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 86, 'prompt_tokens': 682, 'total_tokens': 768, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'solar-pro2-250909', 'system_fingerprint': None, 'id': '37df693b-c96e-440c-8257-b928d4e05a01', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--bb7bb29f-23f3-4d89-aecd-5884b8a4ccb9-0', tool_calls=[{'name': 'multiply', 'args': {'a': 3, 'b': 5}, 'id': 'chatcmpl-tool-99c188eebb814a838f6526d0c3606084', 'type': 'tool_call'}], usage_metadata={'input_tokens': 682, 'output_tokens': 86, 'total_tokens': 768, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})\n"
     ]
    }
   ],
   "source": [
    "tool_result = llm_with_tools.invoke(message_list)\n",
    "\n",
    "pprint(tool_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `message_list`ì˜ ìˆœì„œë¥¼ ê¸°ì–µí•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='3 ê³±í•˜ê¸° 5ëŠ”?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='[ì£¼ì–´ì§„ ì§ˆë¬¸ì€ \"3 ê³±í•˜ê¸° 5\"ì˜ ê²°ê³¼ë¥¼ ë¬»ëŠ” ê²ƒìœ¼ë¡œ, ì´ëŠ” ì§ì ‘ì ìœ¼ë¡œ ê³±ì…ˆ ì—°ì‚°ì´ í•„ìš”í•©ë‹ˆë‹¤. ë”°ë¼ì„œ \\'multiply\\' í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ëŠ” ê²ƒì´ í•„ìˆ˜ì ì…ë‹ˆë‹¤. ë‹¤ë¥¸ ë°©ë²•ìœ¼ë¡œëŠ” ì¼ë°˜ ì§€ì‹ìœ¼ë¡œë„ ë‹µí•  ìˆ˜ ìˆì§€ë§Œ, ê·œì¹™ì— ë”°ë¼ í•¨ìˆ˜ ì‚¬ìš©ì´ í•„ìš”í•œ ê²½ìš°ì—ë§Œ í˜¸ì¶œí•´ì•¼ í•˜ë©°, ì´ ê²½ìš° ê³±ì…ˆ ì—°ì‚°ì´ ì§ˆë¬¸ì˜ í•µì‹¬ì´ë¯€ë¡œ í•¨ìˆ˜ í˜¸ì¶œì´ ì •ë‹¹í•©ë‹ˆë‹¤.] \\n\\nì •ë‹µ: 15', additional_kwargs={'tool_calls': [{'id': 'chatcmpl-tool-638066a86a0143c682396fe4fde379e5', 'function': {'arguments': '{\"a\": 3, \"b\": 5}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 89, 'prompt_tokens': 578, 'total_tokens': 667, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'solar-pro2-250909', 'system_fingerprint': None, 'id': '11c36d9a-83e6-406f-b0a9-0ee6e9525b33', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--1e6c9b67-caf5-4549-aac5-abddf1b12069-0', tool_calls=[{'name': 'multiply', 'args': {'a': 3, 'b': 5}, 'id': 'chatcmpl-tool-638066a86a0143c682396fe4fde379e5', 'type': 'tool_call'}], usage_metadata={'input_tokens': 578, 'output_tokens': 89, 'total_tokens': 667, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " ToolMessage(content='15', name='multiply', tool_call_id='chatcmpl-tool-638066a86a0143c682396fe4fde379e5')]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mylangchain-app-SBe-Yh6W-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
