{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PromptTemplate \n",
    "* [PromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.prompt.PromptTemplate.html#langchain_core.prompts.prompt.PromptTemplate)\n",
    "* [ChatPromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html#langchain_core.prompts.chat.ChatPromptTemplate)\n",
    "* [ChatMessagePromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatMessagePromptTemplate.html#langchain_core.prompts.chat.ChatMessagePromptTemplate)\n",
    "* [FewShotPromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.few_shot.FewShotPromptTemplate.html#langchain_core.prompts.few_shot.FewShotPromptTemplate)\n",
    "* PartialPrompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# poetry add python-dotenv langchain langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# .env 파일을 불러와서 환경 변수로 설정\n",
    "load_dotenv(dotenv_path='../.env')\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1) PromptTemplate 의 from_template() 함수 사용\n",
    "* 주로 LLM(텍스트 완성형 모델, ex. Ollama, GPT-3.5)과 함께 사용\n",
    "* 하나의 문자열 프롬프트를 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ChatGPT는 대규모 텍스트 데이터를 이용해 **자기지도학습**(self‑supervised learning) 방식으로 사전 학습을 '\n",
      " '진행합니다. 이 과정에서 모델은 앞뒤 문맥을 예측하도록 훈련되어, 언어의 통계적 패턴과 의미 관계를 스스로 학습합니다. 이후 특정 작업에 '\n",
      " '맞게 **미세조정**(fine‑tuning)이나 **프롬프트 엔지니어링**을 통해 원하는 출력 형태를 구현합니다.')\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from pprint import pprint\n",
    "\n",
    "template_text = \"{model_name} 모델의 학습 원리를 {count} 문장으로 한국어로 답변해 주세요.\"\n",
    "\n",
    "# PromptTemplate 인스턴스를 생성\n",
    "prompt_template = PromptTemplate.from_template(template_text)\n",
    "\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"openai/gpt-oss-120b\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "chain = prompt_template | llm | StrOutputParser()\n",
    "response = chain.invoke({\"model_name\":\"ChatGPT\", \"count\":3})\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) PromptTemplate 결합하기\n",
    "* 동일한 Prompt 패턴을 사용하지만 여러 개의 질문을 작성해서 LLM을 실행할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['count', 'language', 'model_name'] input_types={} partial_variables={} template='{model_name} 모델의 학습 원리를 {count} 문장으로 한국어로 답변해 주세요.\\n\\n 그리고 {model_name} 모델의 장점을 요약 정리해 주세요\\n\\n {model_name} 모델과 비슷한 AI 모델은 어떤 것이 있나요? 모델명은 {language}로 답변해 주세요.'\n",
      "('**ChatGPT 모델의 학습 원리 (3문장)**  \\n'\n",
      " '1. 대규모 텍스트 코퍼스를 사용해 사전 학습(pre‑training) 단계에서 문맥을 예측하는 언어 모델로 먼저 훈련됩니다.  \\n'\n",
      " '2. 이후 인간이 만든 질문‑답변 쌍이나 지시문을 이용해 강화 학습(RLHF, Reinforcement Learning from '\n",
      " 'Human Feedback)으로 모델을 미세 조정합니다.  \\n'\n",
      " '3. 이 두 단계가 결합돼 모델은 다양한 주제와 형식에 대해 자연스럽고 일관된 응답을 생성할 수 있게 됩니다.  \\n'\n",
      " '\\n'\n",
      " '**ChatGPT의 주요 장점**  \\n'\n",
      " '- 방대한 사전 지식과 문맥 이해 능력으로 다양한 분야의 질문에 신속히 답변한다.  \\n'\n",
      " '- 인간 피드백을 반영한 강화 학습 덕분에 대화 흐름이 자연스럽고 사용자의 의도에 맞는 출력을 제공한다.  \\n'\n",
      " '- 멀티턴 대화, 코드 생성, 요약, 번역 등 여러 작업을 하나의 모델로 수행할 수 있어 활용도가 높다.  \\n'\n",
      " '\\n'\n",
      " '**ChatGPT와 비슷한 AI 모델 (영어명)**  \\n'\n",
      " '- GPT‑4 (OpenAI)  \\n'\n",
      " '- LLaMA\\u202f2 (Meta)  \\n'\n",
      " '- Claude\\u202f3 (Anthropic)  \\n'\n",
      " '- Gemini\\u202f1.5 (Google DeepMind)  \\n'\n",
      " '- Mistral‑7B (Mistral AI)  \\n'\n",
      " '- Falcon‑180B (Technology Innovation Institute)  \\n'\n",
      " '- BLOOM (BigScience)  ')\n"
     ]
    }
   ],
   "source": [
    "template_text = \"{model_name} 모델의 학습 원리를 {count} 문장으로 한국어로 답변해 주세요.\"\n",
    "\n",
    "# PromptTemplate 인스턴스를 생성\n",
    "prompt_template = PromptTemplate.from_template(template_text)\n",
    "\n",
    "# 템플릿에 값을 채워서 프롬프트를 완성\n",
    "filled_prompt = prompt_template.format(model_name=\"ChatGPT\", count=3)\n",
    "\n",
    "# 문자열 템플릿 결합 (PromptTemplate + PromptTemplate + 문자열)\n",
    "combined_prompt = (\n",
    "              prompt_template\n",
    "              + PromptTemplate.from_template(\"\\n\\n 그리고 {model_name} 모델의 장점을 요약 정리해 주세요\")\n",
    "              + \"\\n\\n {model_name} 모델과 비슷한 AI 모델은 어떤 것이 있나요? 모델명은 {language}로 답변해 주세요.\"\n",
    ")\n",
    "combined_prompt.format(model_name=\"ChatGPT\", count=3, language=\"영어\")\n",
    "print(combined_prompt)\n",
    "\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "chain = combined_prompt | llm | StrOutputParser()\n",
    "response = chain.invoke({\"model_name\":\"ChatGPT\", \"count\":3, \"language\":\"영어\"})\n",
    "\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PromptTemplate 의 파라미터를 배열 형태로 하여 여러개 사용하는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GPT-4 모델의 학습 원리를 3 문장으로 한국어로 답변해 주세요.', 'Gemini 모델의 학습 원리를 4 문장으로 한국어로 답변해 주세요.', 'claude 모델의 학습 원리를 4 문장으로 한국어로 답변해 주세요.']\n",
      "<class 'str'> GPT-4 모델의 학습 원리를 3 문장으로 한국어로 답변해 주세요.\n",
      "('GPT‑4는 대규모 텍스트 데이터를 사용해 다음에 올 단어를 예측하도록 학습하는 자기지도 학습 방식을 사용합니다. 이 과정에서 트랜스포머 '\n",
      " '아키텍처의 다중‑헤드 어텐션을 통해 문맥을 장거리에 걸쳐 효율적으로 파악하고, 파라미터를 최적화해 언어 패턴을 일반화합니다. 최종 모델은 '\n",
      " '사전 학습된 가중치를 기반으로 다양한 다운스트림 작업에 맞게 미세조정하거나 프롬프트 엔지니어링으로 활용됩니다.')\n",
      "<class 'str'> Gemini 모델의 학습 원리를 4 문장으로 한국어로 답변해 주세요.\n",
      "('Gemini 모델은 대규모 텍스트와 멀티모달 데이터를 수집해, 트랜스포머 기반의 신경망에 입력합니다.  \\n'\n",
      " '수집된 데이터를 이용해 **자기 지도 학습**(self‑supervised learning)으로 사전 학습(pre‑training)을 '\n",
      " '수행해, 문맥을 예측하거나 이미지‑텍스트 연관성을 학습합니다.  \\n'\n",
      " '그 후, 특정 작업(예: 질문‑응답, 번역, 이미지 캡션 생성 등)에 맞춰 **지도 학습**(supervised '\n",
      " 'fine‑tuning)이나 **강화 학습**(RLHF)으로 미세 조정하여 성능을 최적화합니다.  \\n'\n",
      " '전체 과정은 대규모 병렬 연산을 지원하는 GPU/TPU 클러스터에서 수주에서 수개월에 걸쳐 진행됩니다.')\n",
      "<class 'str'> claude 모델의 학습 원리를 4 문장으로 한국어로 답변해 주세요.\n",
      "('Claude 모델은 대규모 텍스트 데이터를 활용해 **사전 학습(Pre‑training)** 단계에서 언어의 통계적 패턴과 문맥 정보를 '\n",
      " '학습합니다.  \\n'\n",
      " '그 후 **지도 학습(Supervised Fine‑tuning)**을 통해 인간이 만든 예시 답변을 제공받아, 특정 질문에 대한 적절한 '\n",
      " '응답 방식을 익힙니다.  \\n'\n",
      " '또한 **보상 학습(Reinforcement Learning from Human Feedback, RLHF)**을 적용해, 인간 평가자가 '\n",
      " '선호하는 답변을 보상으로 삼아 모델의 출력을 최적화합니다.  \\n'\n",
      " '이러한 단계들을 반복하면서 Claude는 자연스러운 대화와 다양한 작업 수행 능력을 갖춘 언어 모델로 발전합니다.')\n"
     ]
    }
   ],
   "source": [
    "template_text = \"{model_name} 모델의 학습 원리를 {count} 문장으로 한국어로 답변해 주세요.\"\n",
    "\n",
    "# PromptTemplate 인스턴스를 생성\n",
    "prompt_template = PromptTemplate.from_template(template_text)\n",
    "\n",
    "questions = [\n",
    "    {\"model_name\": \"GPT-4\", \"count\": 3},\n",
    "    {\"model_name\": \"Gemini\", \"count\": 4},\n",
    "    {\"model_name\": \"claude\", \"count\": 4},\n",
    "]\n",
    "\n",
    "# 여러 개의 프롬프트를 미리 생성\n",
    "formatted_prompts = [prompt_template.format(**q) for q in questions]\n",
    "print(formatted_prompts)  # 미리 생성된 질문 목록 확인\n",
    "\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "for prompt in formatted_prompts:\n",
    "    print(type(prompt), prompt)\n",
    "    response = llm.invoke(prompt)\n",
    "    pprint(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) ChatPromptTemplate\n",
    "* Tuple 형태의 system, user, assistant 메시지 지원\n",
    "* 여러 개의 메시지를 조합하여 LLM에게 전달 가능\n",
    "* 간결성과 가독성이 높고 단순한 구조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='This system is an expert in answering questions about AI. Please provide clear and detailed explanations.', additional_kwargs={}, response_metadata={}), HumanMessage(content='ChatGPT 모델의 학습 원리를 설명해 주세요.', additional_kwargs={}, response_metadata={})]\n",
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "## ChatGPT 모델이 어떻게 학습되는지  \n",
      "(한국어로 자세히 설명합니다)\n",
      "\n",
      "---\n",
      "\n",
      "### 1. 전체 흐름 개요  \n",
      "\n",
      "| 단계 | 목적 | 주요 기법 |\n",
      "|------|------|----------|\n",
      "| **데이터 수집·정제** | 다양한 언어·주제의 텍스트 확보 | 웹 크롤링, 책·논문·위키피디아·코드 레포 등 |\n",
      "| **토크나이징** | 텍스트를 모델이 이해할 수 있는 **토큰**(기호)으로 변환 | BPE(Byte‑Pair Encoding)·WordPiece 등 |\n",
      "| **사전 학습 (Pre‑training)** | **다음 토큰 예측**이라는 목표로 언어 구조와 지식 습득 | 트랜스포머(Transformer) 아키텍처, 언어 모델링 손실(Cross‑Entropy) |\n",
      "| **지도 학습 (Supervised Fine‑tuning)** | 사용자가 기대하는 형태(질문‑답변, 지시 수행 등)로 모델을 조정 | 인간이 만든 프롬프트‑응답 쌍을 이용 |\n",
      "| **보상 모델 학습 (Reward Model)** | 인간 피드백을 수치화해 “좋은 답변”을 정의 | 인간 라벨러가 평가한 답변을 기반으로 랭킹 모델 학습 |\n",
      "| **RLHF (Reinforcement Learning from Human Feedback)** | 보상 모델을 이용해 정책을 최적화 → **안전하고 유용한** 응답 생성 | PPO(Proximal Policy Optimization) 등 RL 알고리즘 |\n",
      "| **배포·모니터링** | 실제 서비스에 적용하고 지속적으로 품질·안전성 점검 | 로그 분석, 피드백 루프, 업데이트 사이클 |\n",
      "\n",
      "---\n",
      "\n",
      "### 2. 핵심 기술 상세\n",
      "\n",
      "#### 2.1 토크나이징 (Tokenization)\n",
      "\n",
      "1. **왜 필요한가?**  \n",
      "   - 모델은 숫자(벡터)만 처리할 수 있으므로, 텍스트를 정수 시퀀스로 변환해야 함.  \n",
      "2. **BPE (Byte‑Pair Encoding)**  \n",
      "   - 가장 자주 등장하는 문자 쌍을 반복적으로 병합해 **서브워드(sub‑word)** 토큰을 만든다.  \n",
      "   - 예: “un‑”, “##believ‑”, “##able” 등 → 어휘 크기를 수천~수만 개로 제한하면서도 거의 모든 단어를 표현 가능.  \n",
      "3. **장점**  \n",
      "   - 희귀 단어도 몇 개의 서브워드로 분해 가능 → OOV(out‑of‑vocabulary) 문제 최소화.  \n",
      "\n",
      "#### 2.2 트랜스포머 아키텍처\n",
      "\n",
      "| 구성 요소 | 역할 |\n",
      "|-----------|------|\n",
      "| **입력 임베딩** | 토큰 ID → 고차원 실수 벡터 |\n",
      "| **포지셔널 인코딩** | 순서 정보를 추가 (sin/cos 또는 학습 가능한 방식) |\n",
      "| **멀티‑헤드 셀프‑어텐션** | 각 토큰이 문맥 전체와 어떻게 연관되는지 학습 (Q, K, V 행렬) |\n",
      "| **피드‑포워드 네트워크** | 비선형 변환 (두 개의 선형 레이어 + GELU) |\n",
      "| **잔차 연결 + 레이어 정규화** | 학습 안정성 및 깊은 네트워크 훈련 지원 |\n",
      "| **스택** | 위 블록을 96~200개(모델 규모에 따라) 쌓아 깊은 표현 학습 |\n",
      "\n",
      "- **셀프‑어텐션**이 핵심: 한 토큰이 다른 모든 토큰과 직접 “주의(attention)”를 주고받아 문맥을 파악한다.  \n",
      "- **스케일드 점곱 어텐션**: `Attention(Q,K,V) = softmax(QKᵀ / √d_k) V`  \n",
      "\n",
      "#### 2.3 사전 학습 (Pre‑training)\n",
      "\n",
      "- **목표**: **다음 토큰 예측** (다음에 올 토큰을 맞추는 확률을 최대화)  \n",
      "  \\[\n",
      "  \\mathcal{L} = -\\sum_{t=1}^{T}\\log p(x_t \\mid x_{<t})\n",
      "  \\]\n",
      "- **데이터 규모**: 수백억 ~ 수조 토큰 (예: 2023년 기준 GPT‑4는 1조 토큰 이상)  \n",
      "- **학습 방법**  \n",
      "  - **미니배치**: 수천 개 시퀀스를 한 번에 처리  \n",
      "  - **옵티마이저**: AdamW (weight decay 포함)  \n",
      "  - **학습률 스케줄**: **Warm‑up** → **Cosine decay** 등  \n",
      "  - **정규화**: Dropout, Gradient clipping 등으로 과적합·불안정 방지  \n",
      "\n",
      "#### 2.4 지도 학습 (Supervised Fine‑tuning)\n",
      "\n",
      "- **목표**: 특정 작업(예: 질문‑답변, 코드 생성)에 맞는 입력‑출력 쌍을 학습시켜 **프롬프트 → 기대 응답** 형태를 익힌다.  \n",
      "- **데이터**: 인간 라벨러가 만든 수천~수백만 개의 QA, 지시문‑응답 쌍.  \n",
      "- **손실**: 사전 학습과 동일하게 **Cross‑Entropy**를 사용하지만, 입력‑출력 형식이 고정돼 있다.  \n",
      "\n",
      "#### 2.5 보상 모델 (Reward Model) & RLHF\n",
      "\n",
      "1. **보상 모델 학습**  \n",
      "   - 라벨러가 여러 후보 응답을 **선호도**(예: 1~5점)로 평가.  \n",
      "   - 이 데이터를 이용해 **순위 학습**(Pairwise ranking) 혹은 **회귀** 모델을 학습 → “이 응답이 더 좋은가?”를 예측.  \n",
      "\n",
      "2. **RL 단계**  \n",
      "   - 현재 정책(모델)으로 텍스트를 생성 → 보상 모델이 점수 부여.  \n",
      "   - **PPO** 등 강화학습 알고리즘을 사용해 정책 파라미터를 업데이트, 보상이 높은 방향으로 이동.  \n",
      "\n",
      "3. **왜 필요한가?**  \n",
      "   - 단순히 확률을 높이는 사전 학습만으로는 **안전성·유용성**을 보장하기 어렵다.  \n",
      "   - 인간이 실제로 원하는 “친절하고 정확한” 응답을 명시적으로 학습시킬 수 있다.  \n",
      "\n",
      "---\n",
      "\n",
      "### 3. 학습 과정에서의 주요 하이퍼파라미터\n",
      "\n",
      "| 파라미터 | 의미 | 일반적인 값 (예시) |\n",
      "|----------|------|-------------------|\n",
      "| **모델 크기** (layers, hidden size, heads) | 네트워크 용량 | GPT‑3: 96 layers, 12 k hidden, 96 heads |\n",
      "| **맥스 시퀀스 길이** | 한 번에 처리할 토큰 수 | 2048 ~ 8192 토큰 |\n",
      "| **배치 크기** | 한 스텝에 사용하는 토큰 수 | 0.5 ~ 2 M 토큰 (GPU 메모리 기준) |\n",
      "| **학습률** | 파라미터 업데이트 크기 | 1e‑4 ~ 2e‑5 (warm‑up 후 감소) |\n",
      "| **Adamβ1, β2** | 모멘텀 파라미터 | 0.9, 0.95 |\n",
      "| **Dropout** | 과적합 방지 | 0.1 ~ 0.2 |\n",
      "| **Weight decay** | 정규화 | 0.01 ~ 0.1 |\n",
      "\n",
      "> **Tip**: 대규모 모델은 **학습 효율**을 위해 **ZeRO, FSDP, pipeline parallelism** 같은 분산 학습 기술을 사용한다.\n",
      "\n",
      "---\n",
      "\n",
      "### 4. 학습 인프라와 비용\n",
      "\n",
      "| 요소 | 설명 |\n",
      "|------|------|\n",
      "| **GPU/TPU** | 수천 개의 A100, H100, 혹은 TPU v4 클러스터 |\n",
      "| **분산 프레임워크** | PyTorch + DeepSpeed, Megatron‑LM, TensorFlow + Mesh Tensorflow 등 |\n",
      "| **스토리지** | 수백 TB~PB 규모의 텍스트 데이터 (압축 파일 시스템) |\n",
      "| **전력·시간** | 1조 토큰을 학습하는 데 수백 kWh·수주(weeks) 소요, 비용은 수백만 달러 수준 |\n",
      "| **환경 고려** | 탄소 배출량을 줄이기 위해 친환경 전력 사용·효율적인 스케줄링이 점점 강조됨 |\n",
      "\n",
      "---\n",
      "\n",
      "### 5. 학습 후 활용 (Inference)\n",
      "\n",
      "1. **샘플링 전략**  \n",
      "   - **Greedy**: 가장 확률 높은 토큰 선택 (단순하지만 다양성 부족)  \n",
      "   - **Top‑k**: 상위 k개의 토큰 중 샘플링 (k≈50)  \n",
      "   - **Top‑p (nucleus)**: 누적 확률 p(예: 0.9) 이내 토큰 집합에서 샘플링 → 자연스러운 다양성 제공  \n",
      "   - **Temperature**: 확률 분포를 조절 (τ>1 → 더 무작위, τ<1 → 더 확정적)  \n",
      "\n",
      "2. **컨텍스트 관리**  \n",
      "   - 대화형 서비스에서는 **대화 히스토리**를 일정 길이(예: 4k 토큰)까지 유지하고, 오래된 부분은 요약하거나 삭제한다.  \n",
      "\n",
      "3. **안전 필터링**  \n",
      "   - 사전·사후 필터링(예: 유해 내용 차단, 개인정보 보호)과 **시스템 프롬프트**(행동 가이드)로 모델 출력을 제어한다.  \n",
      "\n",
      "---\n",
      "\n",
      "### 6. 주요 연구·개선 흐름 (최근 동향)\n",
      "\n",
      "| 연구·기술 | 핵심 아이디어 | 적용 사례 |\n",
      "|-----------|----------------|-----------|\n",
      "| **Sparse / Mixture‑of‑Experts (MoE)** | 일부 파라미터만 활성화해 효율성↑, 모델 용량↑ | GLaM, Switch‑Transformer |\n",
      "| **Instruction‑tuned models** | “다양한 지시문에 따라 행동하도록 훈련” | InstructGPT, ChatGPT‑Turbo |\n",
      "| **Self‑alignment** | 모델 자체가 규칙을 학습하도록 하는 메타‑학습 | “Self‑Instruct” 논문 |\n",
      "| **Multimodal extension** | 텍스트 외 이미지·오디오·비디오 입력을 함께 학습 | GPT‑4V, Flamingo |\n",
      "| **Efficient fine‑tuning** | LoRA, adapters 등 파라미터 일부만 업데이트 | 빠른 도메인 맞춤 |\n",
      "\n",
      "---\n",
      "\n",
      "### 7. 요약 (핵심 포인트)\n",
      "\n",
      "1. **대규모 텍스트 코퍼스를 토큰화** → **Transformer** 기반 네트워크에 **다음 토큰 예측** 방식으로 사전 학습.  \n",
      "2. **지도 학습**과 **RLHF**를 통해 인간이 원하는 **지시 수행·안전성**을 부여.  \n",
      "3. **분산 학습 인프라**와 **수많은 하이퍼파라미터**가 성공적인 학습을 좌우한다.  \n",
      "4. **Inference** 단계에서는 샘플링 전략·컨텍스트 관리·안전 필터링이 중요.  \n",
      "5. 최신 연구는 **효율성·다중모달·자율 정렬**을 목표로 지속적으로 진화하고 있다.\n",
      "\n",
      "---\n",
      "\n",
      "#### 참고용 용어 정리\n",
      "\n",
      "| 용어 | 설명 |\n",
      "|------|------|\n",
      "| **토큰** | 텍스트를 나눈 최소 단위 (예: 서브워드, 문자) |\n",
      "| **Cross‑Entropy** | 예측 확률과 실제 레이블 간 차이를 측정하는 손실 |\n",
      "| **Self‑Attention** | 입력 시퀀스 내부의 모든 토큰이 서로를 바라보는 메커니즘 |\n",
      "| **RLHF** | 인간 피드백을 보상으로 활용한 강화학습 |\n",
      "| **PPO** | 정책 최적화에 널리 쓰이는 강화학습 알고리즘 |\n",
      "| **LoRA** | Low‑Rank Adaptation, 파라미터 효율적인 파인튜닝 기법 |\n",
      "\n",
      "---\n",
      "\n",
      "**마무리**  \n",
      "ChatGPT는 “대량의 언어 데이터 → 트랜스포머 → 인간 피드백”이라는 3단계 파이프라인을 통해 **언어 이해·생성 능력**을 습득합니다. 사전 학습이 기초 지식을, 지도 학습·RLHF가 실용적·안전한 행동을 담당한다는 점을 기억하면, 모델이 왜 그렇게 동작하는지 직관적으로 이해할 수 있습니다. 궁금한 부분이 더 있으면 언제든 물어보세요!\n"
     ]
    }
   ],
   "source": [
    "# 2-튜플 형태의 메시지 목록으로 프롬프트 생성 (type, content)\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    # role, message\n",
    "    (\"system\", \"This system is an expert in answering questions about {topic}. Please provide clear and detailed explanations.\"),\n",
    "    (\"human\", \"{model_name} 모델의 학습 원리를 설명해 주세요.\"),\n",
    "])\n",
    "\n",
    "messages = chat_prompt.format_messages(topic=\"AI\", model_name=\"ChatGPT\")\n",
    "print(messages)\n",
    "\n",
    "# 생성한 메시지를 바로 주입하여 호출하기\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "print(type(response))\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "## ChatGPT 모델의 학습 원리\n",
      "\n",
      "ChatGPT는 **대규모 언어 모델**(Large Language Model, LLM)이며, 기본 구조는 **Transformer**라는 딥러닝 아키텍처에 기반합니다. 아래에서는 데이터 준비부터 사전 학습(pre‑training), 미세 조정(fine‑tuning), 그리고 실제 서비스에 적용되는 **RLHF**(Reinforcement Learning from Human Feedback)까지 전체 학습 파이프라인을 단계별로 살펴보겠습니다.\n",
      "\n",
      "---\n",
      "\n",
      "### 1. 모델 구조: Transformer 디코더\n",
      "\n",
      "| 구성 요소 | 역할 |\n",
      "|----------|------|\n",
      "| **입력 임베딩** (Token Embedding) | 텍스트를 정수 토큰으로 변환하고, 각 토큰을 고정 차원의 벡터로 매핑 |\n",
      "| **포지셔널 인코딩** (Positional Encoding) | 순서 정보를 제공 (Transformer 자체는 순서를 인식하지 않으므로) |\n",
      "| **멀티‑헤드 셀프‑어텐션** (Multi‑Head Self‑Attention) | 각 토큰이 문맥 안의 모든 다른 토큰과 어떻게 연관되는지를 학습 |\n",
      "| **피드‑포워드 네트워크** (Feed‑Forward) | 비선형 변환을 통해 표현력을 확대 |\n",
      "| **레이어 정규화 & 잔차 연결** (LayerNorm + Residual) | 학습 안정성과 깊은 네트워크 훈련을 돕는다 |\n",
      "| **출력 소프트맥스** (Softmax) | 다음에 올 토큰의 확률 분포를 계산 |\n",
      "\n",
      "이 구조를 **N개의 레이어**(예: GPT‑3에서는 96층, GPT‑4에서는 더 많음)로 쌓아 깊고 풍부한 언어 표현을 얻습니다.\n",
      "\n",
      "---\n",
      "\n",
      "### 2. 사전 학습 (Pre‑training) – **자기지도 학습 (Self‑Supervised Learning)**\n",
      "\n",
      "1. **데이터 수집**  \n",
      "   - 인터넷에 공개된 웹 페이지, 책, 논문, 위키피디아, 포럼 글 등 방대한 텍스트 코퍼스를 수집합니다.  \n",
      "   - 품질을 높이기 위해 스팸, 저작권 문제가 있는 자료, 개인 정보가 포함된 텍스트는 필터링합니다.\n",
      "\n",
      "2. **토크나이징 (Tokenization)**  \n",
      "   - **Byte‑Pair Encoding (BPE)** 혹은 **SentencePiece** 같은 서브워드 토크나이저를 사용해 어휘(vocabulary)를 만든다.  \n",
      "   - 일반적으로 30k~50k개의 토큰을 갖는 어휘 집합을 구성합니다.\n",
      "\n",
      "3. **학습 목표: 다음 토큰 예측 (Next‑Token Prediction)**  \n",
      "   - 입력 시퀀스 `x = (x₁, x₂, …, x_T)`가 주어지면 모델은 각 위치 `t`에서 **조건부 확률** `P(x_t | x_{<t})` 를 예측하도록 학습합니다.  \n",
      "   - 손실 함수는 **교차 엔트로피 손실**(Cross‑Entropy Loss)이며, 전체 시퀀스에 대해 평균을 취합니다.\n",
      "\n",
      "   \\[\n",
      "   \\mathcal{L}_{\\text{CE}} = -\\frac{1}{T}\\sum_{t=1}^{T}\\log P_\\theta(x_t \\mid x_{<t})\n",
      "   \\]\n",
      "\n",
      "4. **최적화**  \n",
      "   - **AdamW** 옵티마이저와 **학습률 스케줄러**(예: Linear Warm‑up → Cosine Decay)를 사용합니다.  \n",
      "   - 대규모 모델은 **분산 학습**(Data Parallelism, Model Parallelism, Pipeline Parallelism)으로 수천 개 GPU/TPU 클러스터에서 동시에 학습됩니다.  \n",
      "   - 학습 단계는 수백억(10⁹)~수조(10¹²) 토큰을 대상으로 진행됩니다.\n",
      "\n",
      "5. **결과**  \n",
      "   - 모델은 **언어 구조**, **사실적 지식**, **추론 패턴** 등을 암묵적으로 학습합니다.  \n",
      "   - 이 단계만으로도 “문맥에 맞는 텍스트 생성”이라는 기본적인 능력을 갖추게 됩니다.\n",
      "\n",
      "---\n",
      "\n",
      "### 3. 지도 학습 (Supervised Fine‑tuning)\n",
      "\n",
      "사전 학습만으로는 **특정 작업**(예: 질문‑답변, 번역, 코드 생성)에서 최적의 성능을 보장하기 어렵습니다. 따라서 다음과 같은 과정을 거칩니다.\n",
      "\n",
      "1. **데이터 준비**  \n",
      "   - 인간이 만든 **입력‑출력 쌍**(예: 질문과 답변, 프롬프트와 기대 응답)을 수집합니다.  \n",
      "   - 품질을 높이기 위해 검증 단계와 라벨링 가이드라인을 적용합니다.\n",
      "\n",
      "2. **학습 목표**  \n",
      "   - 사전 학습과 동일하게 **다음 토큰 예측**을 사용하지만, 입력 시퀀스는 **프롬프트 + 정답** 형태가 됩니다.  \n",
      "   - 손실 함수 역시 교차 엔트로피이며, 모델은 “주어진 프롬프트에 가장 적절한 답을 생성”하도록 학습됩니다.\n",
      "\n",
      "3. **효과**  \n",
      "   - 모델이 특정 형식(예: 대화형 응답, 코드 블록)이나 도메인(법률, 의학)에서 더 일관된 출력을 내도록 조정됩니다.\n",
      "\n",
      "---\n",
      "\n",
      "### 4. 인간 피드백을 통한 강화 학습 (RLHF)\n",
      "\n",
      "ChatGPT와 같은 대화형 모델은 **사용자 친화성**, **안전성**, **목표 지향성**을 높이기 위해 **RLHF** 과정을 거칩니다.\n",
      "\n",
      "1. **시나리오 생성**  \n",
      "   - 여러 프롬프트에 대해 **다양한 후보 응답**을 모델이 생성합니다.\n",
      "\n",
      "2. **인간 라벨러 평가**  \n",
      "   - 라벨러가 **쌍 비교**(A vs B) 혹은 **절대 점수**(1~5점) 형태로 응답을 평가합니다.  \n",
      "   - 이때 “정확성”, “유용성”, “존중성”, “위험성 감소” 등을 기준으로 합니다.\n",
      "\n",
      "3. **보상 모델 (Reward Model) 학습**  \n",
      "   - 라벨링 결과를 바탕으로 **보상 모델** `R_φ`를 학습합니다.  \n",
      "   - 보상 모델은 텍스트를 입력받아 **스칼라 보상값**을 출력합니다.\n",
      "\n",
      "4. **Proximal Policy Optimization (PPO) 적용**  \n",
      "   - 기존 언어 모델을 **정책(policy)** `π_θ` 로 간주하고, 보상 모델을 이용해 **강화학습**을 수행합니다.  \n",
      "   - 목표는 **보상 기대값**을 최대화하면서 기존 정책과 크게 차이나지 않도록 하는 것입니다.\n",
      "\n",
      "   \\[\n",
      "   \\max_{\\theta}\\ \\mathbb{E}_{\\pi_\\theta}[R_\\phi(\\text{output})] \\quad \\text{s.t.} \\quad \\text{KL}(\\pi_\\theta \\| \\pi_{\\text{old}}) \\leq \\epsilon\n",
      "   \\]\n",
      "\n",
      "5. **안전성 필터링**  \n",
      "   - RLHF 이후에도 **위험성 탐지 모델**(예: 유해 콘텐츠 필터)과 **규칙 기반 차단**을 적용해 최종 출력이 안전하도록 합니다.\n",
      "\n",
      "---\n",
      "\n",
      "### 5. 추론(Inference) 단계\n",
      "\n",
      "1. **프롬프트 입력** → 토크나이징 → 모델에 전달  \n",
      "2. **다음 토큰 확률 분포**를 계산하고, **샘플링 전략**(Greedy, Top‑k, Top‑p/Nucleus, Temperature)으로 토큰을 선택  \n",
      "3. 선택된 토큰을 시퀀스에 추가하고, 2~3 단계를 반복해 원하는 길이까지 텍스트를 생성  \n",
      "\n",
      "> **핵심 포인트**  \n",
      "> - **샘플링 전략**에 따라 답변의 **창의성**과 **일관성**이 달라집니다.  \n",
      "> - 실시간 서비스에서는 **토큰당 지연 시간**을 최소화하기 위해 **양자화(Quantization)**, **지연 파이프라인** 등을 활용합니다.\n",
      "\n",
      "---\n",
      "\n",
      "## 전체 흐름 요약\n",
      "\n",
      "1. **대규모 텍스트 수집 → 토크나이징**  \n",
      "2. **Transformer 기반 모델을 자기지도 학습(다음 토큰 예측)으로 사전 학습**  \n",
      "3. **특정 작업/도메인에 맞춰 지도 학습으로 미세 조정**  \n",
      "4. **인간 피드백을 보상으로 활용한 강화 학습(RLHF)으로 안전하고 유용한 행동을 학습**  \n",
      "5. **추론 시 토큰 샘플링 전략을 적용해 실시간 응답 생성**\n",
      "\n",
      "이러한 단계들을 거쳐 **ChatGPT**는 “주어진 문맥에 맞는 자연스러운 텍스트”를 생성하고, 인간과의 대화에서 **유용하고 안전한** 정보를 제공할 수 있게 됩니다. 궁금한 점이 더 있으면 언제든 물어보세요!\n"
     ]
    }
   ],
   "source": [
    "# 체인을 생성하여 호출하기\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "chain = chat_prompt | llm | StrOutputParser()\n",
    "\n",
    "response = chain.invoke({\"topic\":\"AI\", \"model_name\":\"ChatGPT\"})\n",
    "print(type(response))\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) ChatPromptTemplate\n",
    "* SystemMessagePromptTemplate와 HumanMessagePromptTemplate 클래스 사용\n",
    "* 객체 지향적 접근 - Message 객체를 독립적으로 생성 가능\n",
    "* 여러 조건에 따라 다른 시스템 메시지 선택\n",
    "\n",
    "```python\n",
    "if user_is_beginner:\n",
    "    system_message = SystemMessagePromptTemplate.from_template(\"초보자를 위한 설명: {topic}\")\n",
    "else:\n",
    "    system_message = SystemMessagePromptTemplate.from_template(\"전문가를 위한 상세 분석: {topic}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChatMessagePromptTemplate 활용\n",
    "\n",
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    ChatMessagePromptTemplate\n",
    ")\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 개별 메시지 템플릿 정의\n",
    "system_message = SystemMessagePromptTemplate.from_template(\n",
    "    \"You are an AI expert in {topic}. Please provide clear and detailed explanations.\"\n",
    ")\n",
    "user_message = HumanMessagePromptTemplate.from_template(\n",
    "    \"{question}\"\n",
    ")\n",
    "ai_message = AIMessagePromptTemplate.from_template(\n",
    "    \"This is an example answer about {topic}.\"\n",
    ")\n",
    "\n",
    "# ChatPromptTemplate로 메시지들을 묶기\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    system_message,\n",
    "    user_message,\n",
    "    ai_message\n",
    "])\n",
    "\n",
    "# 메시지 생성\n",
    "messages = chat_prompt.format_messages(topic=\"AI\", question=\"What is deep learning?\")\n",
    "\n",
    "# LLM 호출\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "# 결과 출력\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ChatMessagePromptTemplate는 여러 종류의 메시지(시스템, 인간, AI)를 조합하여 복잡한 프롬프트를 생성할 때 유용합니다.\n",
    "* SystemMessagePromptTemplate: 이 템플릿은 AI 모델에게 역할을 부여하거나 전반적인 규칙을 설정하는 시스템 메시지를 만듭니다. 위의 예시에서는 \"번역을 도와주는 유용한 도우미\"라는 역할을 지정합니다.\n",
    "* HumanMessagePromptTemplate: 이 템플릿은 사용자의 질문이나 요청을 담는 인간 메시지를 만듭니다. 아래의 예시에서는 번역할 텍스트를 입력받습니다.\n",
    "* ChatPromptTemplate.from_messages: 이 클래스 메서드는 시스템 메시지, 인간 메시지 등 여러 종류의 MessagePromptTemplate 객체들을 리스트로 받아 하나의 채팅 프롬프트 템플릿으로 통합합니다.\n",
    "* format_messages: 이 메서드는 정의된 템플릿에 실제 값을 채워 넣어 [SystemMessage, HumanMessage] 형태의 리스트를 반환합니다. 이 리스트는 채팅 모델(Chat Model) 에 바로 전달될 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 임포트\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "# 1. SystemMessagePromptTemplate와 HumanMessagePromptTemplate 생성\n",
    "# SystemMessagePromptTemplate는 모델의 페르소나 또는 기본 지침을 설정합니다.\n",
    "system_template = \"You are a helpful assistant that translates {input_language} to {output_language}.\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
    "\n",
    "# HumanMessagePromptTemplate는 사용자로부터 받는 입력 프롬프트를 정의합니다.\n",
    "human_template = \"{text_to_translate}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "# 2. ChatPromptTemplate 생성\n",
    "# 위에서 만든 두 템플릿을 리스트로 묶어 ChatPromptTemplate을 만듭니다.\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "\n",
    "# 3. 프롬프트 포맷팅\n",
    "# chat_prompt_template.format_messages()를 사용하여 최종 메시지 리스트를 생성합니다.\n",
    "# 이 함수는 딕셔너리 형태의 입력 변수를 받습니다.\n",
    "formatted_prompt = chat_prompt_template.format_messages(\n",
    "    input_language=\"English\",\n",
    "    output_language=\"Korean\",\n",
    "    text_to_translate=\"I love programming.\"\n",
    ")\n",
    "\n",
    "# 4. 결과 출력\n",
    "print(formatted_prompt)\n",
    "\n",
    "# LLM 호출\n",
    "response = llm.invoke(formatted_prompt)\n",
    "\n",
    "# 결과 출력\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4) FewShotPromptTemplate\n",
    "* FewShotPromptTemplate은 모델이 특정 형식을 따르게 하거나, 일관된 응답을 생성하도록 유도할 때 유용합니다.\n",
    "* 도메인 지식이 필요하거나, AI가 오답을 줄이고 더 신뢰할 만한 답변을 생성하도록 해야 할 때 효과적입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4-1) PromptTemplate을 사용하지 않는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "태양계에는 8개의 행성이 있습니다. \n",
      "\n",
      "1.  수성: 태양과 가장 가까운 행성으로, 표면이 암석으로 구성되어 있고 극도로 높은 온도와 낮은 온도가 반복됩니다.\n",
      "2.  금성: 태양계에서 두 번째로 가까운 행성으로, 두꺼운 대기로 인해 극심한 온실 효과가 발생하여 매우 뜨겁습니다.\n",
      "3.  지구: 우리가 사는 행성으로, 물과 대기가 있어 생명체가 존재할 수 있습니다.\n",
      "4.  화성: 태양계에서 네 번째로 가까운 행성으로, 붉은색의 모래사막으로 덮여 있고 물과 생명체의 존재 가능성이 있습니다.\n",
      "5.  목성: 태양계에서 가장 큰 행성으로, 가스 거인이며 강력한 자기장과 수많은 위성을 가지고 있습니다.\n",
      "6.  토성: 태양계에서 두 번째로 큰 행성으로, 가스 거인이며 아름다운 고리를 가지고 있습니다.\n",
      "7.  천왕성: 태양계에서 일곱 번째로 가까운 행성으로, 가스 거인이며 자전축이 기울어져 있어 극단적인 기후 변화를 경험합니다.\n",
      "8.  해왕성: 태양계에서 가장 먼 행성으로, 가스 거인이며 강한 바람과 극적인 기후 변화를 가지고 있습니다.\n",
      "\n",
      "이러한 행성들은 각각 고유한 특징과 성질을 가지고 있으며, 태양계에서 중요한 역할을 합니다.\n"
     ]
    }
   ],
   "source": [
    "# PromptTemplate을 사용하지 않는 경우\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# model\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "# chain 실행\n",
    "result = llm.invoke(\"태양계의 행성들을 간략히 정리해 주세요.\")\n",
    "\n",
    "print(type(result))\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4-2) FewShotChatMessagePromptTemplate 사용하는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first=ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='당신은 초등학생도 쉽게 이해할 수 있도록 쉽게 설명하는 과학 교육자입니다.'), additional_kwargs={}), FewShotChatMessagePromptTemplate(examples=[{'input': '뉴턴의 운동 법칙을 요약해 주세요.', 'output': '### 뉴턴의 운동 법칙\\n1. **관성의 법칙**: 힘이 작용하지 않으면 물체는 계속 같은 상태를 유지합니다.\\n2. **가속도의 법칙**: 물체에 힘이 작용하면, 힘과 질량에 따라 가속도가 결정됩니다.\\n3. **작용-반작용 법칙**: 모든 힘에는 크기가 같고 방향이 반대인 힘이 작용합니다.'}, {'input': '지구의 대기 구성 요소를 알려주세요.', 'output': '### 지구 대기의 구성\\n- **질소 (78%)**: 대기의 대부분을 차지합니다.\\n- **산소 (21%)**: 생명체가 호흡하는 데 필요합니다.\\n- **아르곤 (0.93%)**: 반응성이 낮은 기체입니다.\\n- **이산화탄소 (0.04%)**: 광합성 및 온실 효과에 중요한 역할을 합니다.'}], input_variables=[], input_types={}, partial_variables={}, example_prompt=ChatPromptTemplate(input_variables=['input', 'output'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=['output'], input_types={}, partial_variables={}, template='{output}'), additional_kwargs={})])), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})]) middle=[] last=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000001A62DC1A150>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001A630C84E00>, root_client=<openai.OpenAI object at 0x000001A62F0D1880>, root_async_client=<openai.AsyncOpenAI object at 0x000001A630BB3080>, model_name='openai/gpt-oss-120b', temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://api.groq.com/openai/v1')\n",
      "## 태양계의 행성 8개 (태양에서 가까운 순서)\n",
      "\n",
      "| 순서 | 행성 | 특징 | 크기·비교 | 주요 위성 |\n",
      "|------|------|------|-----------|-----------|\n",
      "| 1 | **수성 (Mercury)** | 가장 작은 행성, 대기가 거의 없음 | 지구 지름의 약 38% | 위성 없음 |\n",
      "| 2 | **금성 (Venus)** | 두꺼운 이산화탄소 대기·극심한 온실효과, “지구의 쌍둥이”라 불림 | 지구와 비슷한 크기(지구 지름 95%) | 위성 없음 |\n",
      "| 3 | **지구 (Earth)** | 물이 액체 상태로 존재, 생명체가 사는 유일한 행성 | 기준(지구) | 달 (Moon) |\n",
      "| 4 | **화성 (Mars)** | 붉은 색 먼지·산소가 거의 없는 얇은 대기, 과거에 물이 있었을 가능성 | 지구 지름의 53% | 포보스·디모스 (두 개의 작은 위성) |\n",
      "| 5 | **목성 (Jupiter)** | 가장 큰 행성, 가스 거인, 강한 자기장·수많은 폭풍 | 지구 지름의 11배, 질량은 318배 | 갈릴레오 위성 4개 (이오, 유로파, 가니메데, 칼리스토) 등 80여 개 |\n",
      "| 6 | **토성 (Saturn)** | 아름다운 고리 시스템으로 유명 | 지구 지름의 9.5배, 질량은 95배 | 타이탄, 레아 등 80여 개 위성 |\n",
      "| 7 | **천왕성 (Uranus)** | 옆으로 누워서 회전(자전축 기울기 98°), 푸른 색은 메탄 | 지구 지름의 4배, 질량은 14.5배 | 티타니아, 오베론 등 27개 위성 |\n",
      "| 8 | **해왕성 (Neptune)** | 가장 바깥쪽 가스 행성, 가장 빠른 바람 | 지구 지름의 3.9배, 질량은 17배 | 트리톤, 네레이드 등 14개 위성 |\n",
      "\n",
      "### 간단 요약\n",
      "- **내행성(수성·금성·지구·화성)**: 암석으로 이루어진 작은 행성, 태양에 가깝다.  \n",
      "- **외행성(목성·토성·천왕성·해왕성)**: 주로 가스로 이루어진 거대한 행성, ‘가스/얼음 거인’이라고 부른다.  \n",
      "\n",
      "각 행성마다 고유한 특징과 위성이 있어, 우리 태양계는 다양하고 흥미로운 천체들로 가득합니다!\n"
     ]
    }
   ],
   "source": [
    "# FewShotChatMessagePromptTemplate 사용하는 경우\n",
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"input\": \"뉴턴의 운동 법칙을 요약해 주세요.\",\n",
    "        \"output\": \"\"\"### 뉴턴의 운동 법칙\n",
    "1. **관성의 법칙**: 힘이 작용하지 않으면 물체는 계속 같은 상태를 유지합니다.\n",
    "2. **가속도의 법칙**: 물체에 힘이 작용하면, 힘과 질량에 따라 가속도가 결정됩니다.\n",
    "3. **작용-반작용 법칙**: 모든 힘에는 크기가 같고 방향이 반대인 힘이 작용합니다.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"지구의 대기 구성 요소를 알려주세요.\",\n",
    "        \"output\": \"\"\"### 지구 대기의 구성\n",
    "- **질소 (78%)**: 대기의 대부분을 차지합니다.\n",
    "- **산소 (21%)**: 생명체가 호흡하는 데 필요합니다.\n",
    "- **아르곤 (0.93%)**: 반응성이 낮은 기체입니다.\n",
    "- **이산화탄소 (0.04%)**: 광합성 및 온실 효과에 중요한 역할을 합니다.\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# 예제 프롬프트 템플릿\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# FewShotChatMessagePromptTemplate 적용\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "# 최종 프롬프트 구성\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"당신은 초등학생도 쉽게 이해할 수 있도록 쉽게 설명하는 과학 교육자입니다.\"),\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 모델 생성 및 체인 구성\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.0)\n",
    "chain = final_prompt | llm\n",
    "print(chain)\n",
    "\n",
    "# 테스트 실행\n",
    "result = chain.invoke({\"input\": \"태양계의 행성들을 간략히 정리해 주세요.\"})\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5-1) PartialPrompt \n",
    "* 프롬프트를 더 동적으로 활용할 수 있으며, AI 응답을 더 일관성 있게 조정 가능함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 계절을 결정하는 함수 (남반구/북반구 고려)\n",
    "def get_current_season(hemisphere=\"north\"):\n",
    "    month = datetime.now().month\n",
    "\n",
    "    if hemisphere == \"north\":  # 북반구 (기본값)\n",
    "        if 3 <= month <= 5:\n",
    "            return \"봄\"\n",
    "        elif 6 <= month <= 8:\n",
    "            return \"여름\"\n",
    "        elif 9 <= month <= 11:\n",
    "            return \"가을\"\n",
    "        else:\n",
    "            return \"겨울\"\n",
    "    else:  # 남반구 (계절 반대)\n",
    "        if 3 <= month <= 5:\n",
    "            return \"가을\"\n",
    "        elif 6 <= month <= 8:\n",
    "            return \"겨울\"\n",
    "        elif 9 <= month <= 11:\n",
    "            return \"봄\"\n",
    "        else:\n",
    "            return \"여름\"\n",
    "\n",
    "# 프롬프트 템플릿 정의 (부분 변수 적용)\n",
    "prompt = PromptTemplate(\n",
    "    template=\"{season}에 일어나는 대표적인 지구과학 현상은 {phenomenon}이 맞나요? {season}에 주로 발생하는 지구과학 현상을 3개 알려주세요\",\n",
    "    input_variables=[\"phenomenon\"],  # 사용자 입력 필요\n",
    "    partial_variables={\"season\": get_current_season()}  # 동적으로 계절 값 할당\n",
    ")\n",
    "\n",
    "# OpenAI 모델 초기화\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.0)\n",
    "\n",
    "# 특정 계절의 현상 질의\n",
    "query = prompt.format(phenomenon=\"태풍 발생\")\n",
    "result = llm.invoke(query)\n",
    "\n",
    "\n",
    "# 결과 출력\n",
    "print(f\" 프롬프트: {query}\")\n",
    "print(f\" 모델 응답: {result.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 계절을 결정하는 함수 (남반구/북반구 고려)\n",
    "def get_current_season(hemisphere=\"north\"):\n",
    "    month = datetime.now().month\n",
    "\n",
    "    if hemisphere == \"north\":  # 북반구 (기본값)\n",
    "        if 3 <= month <= 5:\n",
    "            return \"봄\"\n",
    "        elif 6 <= month <= 8:\n",
    "            return \"여름\"\n",
    "        elif 9 <= month <= 11:\n",
    "            return \"가을\"\n",
    "        else:\n",
    "            return \"겨울\"\n",
    "    else:  # 남반구 (계절 반대)\n",
    "        if 3 <= month <= 5:\n",
    "            return \"가을\"\n",
    "        elif 6 <= month <= 8:\n",
    "            return \"겨울\"\n",
    "        elif 9 <= month <= 11:\n",
    "            return \"봄\"\n",
    "        else:\n",
    "            return \"여름\"\n",
    "\n",
    "# Step 1: 현재 계절 결정\n",
    "season = get_current_season(\"north\")  # 계절 값 얻기\n",
    "print(f\"현재 계절: {season}\")\n",
    "\n",
    "# Step 2: 해당 계절의 자연 현상 추천\n",
    "prompt2 = ChatPromptTemplate.from_template(\n",
    "    \"{season}에 주로 발생하는 대표적인 지구과학 현상 3가지를 알려주세요. \"\n",
    "    \"각 현상에 대해 간단한 설명을 포함해주세요.\"\n",
    ")\n",
    "\n",
    "# OpenAI 모델 사용\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.0)\n",
    "llm = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.0\n",
    ")\n",
    "\n",
    "# 체인 2: 자연 현상 추천 (입력: 계절 → 출력: 자연 현상 목록)\n",
    "chain2 = (\n",
    "    {\"season\": lambda x : season}  # chain1의 출력을 season 변수로 전달\n",
    "    | prompt2\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 실행: 현재 계절에 따른 자연 현상 추천\n",
    "response = chain2.invoke({})\n",
    "print(f\"\\n {season}에 발생하는 자연 현상:\\n{response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5-2) PartialPrompt \n",
    "* API 호출 데이터, 시간 정보, 사용자 정보 등을 반영할 때 매우 유용함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 프롬프트: 현재 1달러 = 1377.98원 기준으로 환율 정보를 알려드립니다. 이에 대한 분석을 제공해 주세요.\n",
      " 모델 응답: ### 1 USD = 1,377.98 KRW 환율에 대한 종합 분석\n",
      "\n",
      "| 구분 | 내용 |\n",
      "|------|------|\n",
      "| **현재 환율** | 1 USD = 1,377.98 KRW (2025‑09‑18 기준) |\n",
      "| **주요 변동 요인** | • 미국 연방준비제도(Fed)·한국은행(BOK) 금리 차이<br>• 양국 물가·인플레이션 전망<br>• 글로벌 위험 선호도·달러 강세/약세 흐름<br>• 한국 무역수지·수출입 구조 변화 |\n",
      "| **최근 12개월 추이** | - 2024 초: 1,300 KRW 수준 (달러 약세)<br>- 2024 중반: 1,350 KRW까지 상승 (미국 금리 인상 지속)<br>- 2024 말~2025 초: 1,380 KRW 수준 유지 (한국 금리 인하 기대감 감소)<br>- 현재 1,378 KRW는 연간 평균 대비 약 +2 % 수준 |\n",
      "| **역사적 비교** | - 2000년대 초반: 1,200 KRW 수준 (달러 약세)<br>- 2008년 금융위기 이후: 1,100 KRW 수준 (달러 강세)<br>- 2010‑2015: 1,100~1,200 KRW (안정기)<br>- 2020‑2022: 1,150~1,300 KRW (코로나·미국 금리 인상)<br>현재는 **역사적 고점(2023 말 1,400 KRW) 근처**에 해당합니다. |\n",
      "\n",
      "---\n",
      "\n",
      "## 2. 환율 변동에 영향을 미치는 주요 거시경제 요인\n",
      "\n",
      "| 요인 | 현재 상황 | 환율에 미치는 영향 |\n",
      "|------|----------|-------------------|\n",
      "| **미국 금리 정책** | 연방준비제도(Fed) 금리 **5.25 %** 수준 유지, 인플레이션 억제 목표로 추가 인상 가능성 낮음 | 높은 금리는 달러 매력을 유지 → 원·달러 환율 상승 압력 |\n",
      "| **한국 금리 정책** | 한국은행 기준금리 **3.50 %** (2025 Q2) – 물가 상승세 억제와 경기 부양 사이에서 정책 금리 동결 | 금리 격차가 축소될 경우 원화 약세 지속 가능성 감소 |\n",
      "| **물가·인플레이션** | 미국 CPI 연율 **3.2 %** (최근 3개월 평균) <br>한국 CPI 연율 **2.7 %** | 미국 물가가 상대적으로 높아 달러 수요가 유지되지만, 인플레이션 격차가 크게 벌어지지 않아 급격한 변동은 제한적 |\n",
      "| **무역수지** | 2024‑2025년 수출은 **반도체·디스플레이·전기차 부품** 중심으로 견조, 무역흑자 30~40 억 USD 수준 유지 | 무역흑자는 원화 강세 요인이나, 수출품 가격이 달러표시이므로 원화 약세가 수출 이익을 보호하는 효과도 있음 |\n",
      "| **외국인 직접투자(FDI)** | 2025년 상반기 한국에 대한 FDI 흐름은 **전년 대비 8 % 증가** (주로 반도체·배터리) | 자본 유입은 원화 수요를 늘려 환율 하락 요인 |\n",
      "| **글로벌 위험 선호** | 최근 지정학적 긴장(우크라이나·중동)과 중국 경기 둔화 우려가 지속 | 위험 회피 시 달러 수요가 증가해 원·달러 환율 상승 압력 |\n",
      "\n",
      "---\n",
      "\n",
      "## 3. 단기(3‑6개월) 전망\n",
      "\n",
      "| 시나리오 | 핵심 전제 | 예상 환율 범위 |\n",
      "|----------|-----------|----------------|\n",
      "| **베어(달러 강세) 시나리오** | Fed가 금리 인상 가능성을 재점화, 한국 금리 동결·경기 둔화 우려 | 1,400 ~ 1,440 KRW |\n",
      "| **불(원화 강세) 시나리오** | 한국 금리 인상 또는 금리 격차 축소, 무역흑자 확대·외국인 투자 급증 | 1,330 ~ 1,360 KRW |\n",
      "| **중립 시나리오** | 현재 금리 차 유지, 물가 상승률 비슷하게 유지, 변동성 완화 | 1,370 ~ 1,390 KRW (현재 수준 유지) |\n",
      "\n",
      "**가능성 판단**  \n",
      "- Fed가 급격히 금리를 인상할 여지는 낮아 보이므로 **베어 시나리오**는 제한적입니다.  \n",
      "- 한국은행이 인플레이션 억제를 위해 **점진적 금리 인상**(예: 3.75 %~4.00 %)을 선택한다면 원화 강세 가능성이 높아집니다.  \n",
      "- 따라서 **중립·불 시나리오**가 가장 현실적인 전망입니다.\n",
      "\n",
      "---\n",
      "\n",
      "## 4. 기업·투자자·소비자를 위한 실무적 시사점\n",
      "\n",
      "| 대상 | 전략/대응 방안 |\n",
      "|------|----------------|\n",
      "| **수출기업** (반도체·배터리·자동차) | - **환위험 헤지**: 3~6개월 선물·옵션 계약 활용<br>- **가격전략**: 계약서에 환율 변동조항(예: KRW/USD ± 5 % 구간) 삽입<br>- **다변화**: 매출을 달러 외에도 유로·위안 등 다른 통화로 분산 |\n",
      "| **수입기업** (원자재·부품) | - **선물 매수**: 원달러 선물 매수로 비용 상승 방어<br>- **재고 관리**: 환율 상승기에 재고를 미리 확보해 비용 고정 |\n",
      "| **외국인 투자자** | - **환 헤지 펀드**: KRW‑USD 헤지 펀드 활용<br>- **채권 포트폴리오**: 한국 국채·기업채는 원화 약세 시 원리금 손실 위험 → 헤지 필요 |\n",
      "| **개인 투자자** | - **달러 저축·예금**: 원화 약세 지속 시 달러예금 금리(연 3~4 %)가 매력적<br>- **환율 변동성 활용**: 단기 트레이딩(스프레드 매매) 시 1 %~2 % 변동폭 활용 가능 |\n",
      "| **여행·소비자** | - **시기 선택**: 여행 시점 전 환전 시점 선택 (예: 환율이 1,350 KRW 이하일 때 미리 구매)<br>- **카드 사용**: 해외 결제 시 현지 통화 결제(USD)보다 원화 결제(원화 자동 변환) 비용 차이 검토 |\n",
      "\n",
      "---\n",
      "\n",
      "## 5. 정책 입안자를 위한 권고\n",
      "\n",
      "1. **금리 정책 조정**  \n",
      "   - 인플레이션이 목표치(2 %)에 근접하면 **점진적 금리 인상**을 검토해 원화 가치를 안정시킬 수 있습니다.  \n",
      "2. **외환 시장 유동성 공급**  \n",
      "   - 급격한 원·달러 변동성을 억제하기 위해 **외환 스와프·시장 조성**을 확대할 필요가 있습니다.  \n",
      "3. **수출 경쟁력 강화**  \n",
      "   - 환율 변동에 따른 수출기업 손실을 최소화하기 위해 **수출보험·환위험 보증** 제도를 확대하고, **다변화된 통화 결제**를 촉진합니다.  \n",
      "4. **투자 환경 조성**  \n",
      "   - 외국인 직접투자를 유치하기 위해 **환위험 헤지 도구**(선물·옵션) 시장 인프라를 강화하고, **투자자 보호** 메커니즘을 명확히 합니다.  \n",
      "\n",
      "---\n",
      "\n",
      "## 6. 결론\n",
      "\n",
      "- 현재 1 USD = 1,377.98 KRW는 **역사적 고점에 근접**한 수준이며, **미국과 한국의 금리 격차, 물가 차이, 무역·투자 흐름**이 복합적으로 작용하고 있습니다.  \n",
      "- 단기적으로는 **큰 변동 없이 1,370 ~ 1,390 KRW** 구간을 유지할 가능성이 높으며, **한국 금리 인상** 혹은 **미국 금리 동결·완화**가 발생하면 원화 강세가 나타날 여지가 있습니다.  \n",
      "- 기업·투자자는 **환위험 헤지**와 **다변화된 통화 포트폴리오**를 통해 변동성을 관리하고, 정책 입안자는 **금리·유동성·수출지원**을 통해 환율 안정을 도모해야 합니다.  \n",
      "\n",
      "> **핵심 포인트**: 현재 환율은 고점에 가깝지만, 금리 격차와 무역·투자 흐름에 따라 **중립 또는 약간의 원화 강세**가 예상됩니다. 위험 관리와 전략적 대응이 중요한 시점입니다.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 실시간 환율을 가져오는 함수\n",
    "def get_exchange_rate():\n",
    "    response = requests.get(\"https://api.exchangerate-api.com/v4/latest/USD\")\n",
    "    data = response.json()\n",
    "    return f\"1달러 = {data['rates']['KRW']}원\"\n",
    "\n",
    "# Partial Prompt 활용\n",
    "prompt = PromptTemplate(\n",
    "    template=\"현재 {info} 기준으로 환율 정보를 알려드립니다. 이에 대한 분석을 제공해 주세요.\",\n",
    "    input_variables=[],  # 사용자 입력 없음\n",
    "    partial_variables={\"info\": get_exchange_rate()}  # API에서 가져온 데이터 자동 반영\n",
    ")\n",
    "\n",
    "# LLM 모델 설정\n",
    "#llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.0)\n",
    "\n",
    "# 모델에 프롬프트 전달 및 응답 받기\n",
    "response = llm.invoke(prompt.format())\n",
    "\n",
    "# 결과 출력\n",
    "print(\" 프롬프트:\", prompt.format())\n",
    "print(\" 모델 응답:\", response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mylangchain-app-SBe-Yh6W-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
