{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### LangChain vs LangGraph (feat. LangGraph ê°œë… ì„¤ëª…)\n",
        "* LangGraphì˜ ê°œë…ê³¼ ì£¼ìš” ê¸°ëŠ¥ì„ ì´í•´í•˜ê³ , ì°¨ì´ì ì„ ë¹„êµí•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sk\n",
            "Fy\n"
          ]
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "print(OPENAI_API_KEY[:2])\n",
        "\n",
        "UPSTAGE_API_KEY = os.getenv(\"UPSTAGE_API_KEY\")\n",
        "print(UPSTAGE_API_KEY[30:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\user\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\mylangchain-app-SBe-Yh6W-py3.12\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "client=<openai.resources.chat.completions.completions.Completions object at 0x0000027FCABB0D70> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000027FCC48FC80> model_name='solar-pro' temperature=0.5 model_kwargs={} upstage_api_key=SecretStr('**********') upstage_api_base='https://api.upstage.ai/v1'\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "AIMessage(content='**LangGraph**ëŠ” ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ **ìƒíƒœ ê´€ë¦¬(stateful) ë©€í‹°ëª¨ë‹¬ ì• í”Œë¦¬ì¼€ì´ì…˜**ì„ êµ¬ì¶•í•˜ê¸° ìœ„í•œ ì˜¤í”ˆì†ŒìŠ¤ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤. LangChain íŒ€ì„ ì£¼ë„ë¡œ ê°œë°œë˜ì—ˆìœ¼ë©°, ë³µì¡í•œ ëŒ€í™”í˜• ì‹œìŠ¤í…œ(ì˜ˆ: ì±—ë´‡, ì—ì´ì „íŠ¸, ì›Œí¬í”Œë¡œìš° ìë™í™”)ì„ ì„¤ê³„í•  ë•Œ **ê·¸ë˜í”„ ê¸°ë°˜ì˜ ìƒíƒœ ì¶”ì **ê³¼ **ëª¨ë“ˆì‹ êµ¬ì„±**ì„ ì œê³µí•©ë‹ˆë‹¤.\\n\\n### ì£¼ìš” íŠ¹ì§•\\n1. **ê·¸ë˜í”„ ê¸°ë°˜ ìƒíƒœ ê´€ë¦¬**  \\n   - LLMì˜ ëŒ€í™” íë¦„ì„ **ë…¸ë“œ(Node)ì™€ ì—£ì§€(Edge)**ë¡œ êµ¬ì„±ëœ ê·¸ë˜í”„ë¡œ í‘œí˜„í•©ë‹ˆë‹¤.  \\n   - ê° ë…¸ë“œëŠ” íŠ¹ì • ì‘ì—…(ì˜ˆ: LLM í˜¸ì¶œ, ë„êµ¬ ì‚¬ìš©)ì„ ìˆ˜í–‰í•˜ë©°, ì—£ì§€ëŠ” ìƒíƒœ ì „ì´(transition)ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.  \\n   - ë³µì¡í•œ ëŒ€í™”ì—ì„œë„ **ì´ì „ ì»¨í…ìŠ¤íŠ¸ë¥¼ ìœ ì§€**í•˜ë©° ìœ ì—°í•œ ì›Œí¬í”Œë¡œìš°ë¥¼ êµ¬ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n\\n2. **í™•ì¥ì„±**  \\n   - LangChainì˜ ì»´í¬ë„ŒíŠ¸(LLM, ë©”ëª¨ë¦¬, ë„êµ¬ ë“±)ì™€ í˜¸í™˜ë˜ì–´ ê¸°ì¡´ LangChain ì• í”Œë¦¬ì¼€ì´ì…˜ì„ LangGraphë¡œ ì‰½ê²Œ ë§ˆì´ê·¸ë ˆì´ì…˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  \\n   - ì‚¬ìš©ì ì •ì˜ ë…¸ë“œ/ì—£ì§€ë¥¼ ì¶”ê°€í•´ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ì— ë§ê²Œ í™•ì¥ ê°€ëŠ¥í•©ë‹ˆë‹¤.\\n\\n3. **ì‹¤ì‹œê°„ í˜‘ì—… ì§€ì›**  \\n   - ì—¬ëŸ¬ ì‚¬ìš©ì ë˜ëŠ” ì—ì´ì „íŠ¸ê°€ ë™ì‹œì— ìƒí˜¸ì‘ìš©í•˜ëŠ” ì‹œë‚˜ë¦¬ì˜¤(ì˜ˆ: í˜‘ì—… ë„êµ¬, ê²Œì„)ì— ì í•©í•©ë‹ˆë‹¤.  \\n   - ìƒíƒœ ë™ê¸°í™”ë¥¼ í†µí•´ **ë™ì‹œì„±(concurrency)** ë¬¸ì œë¥¼ í•´ê²°í•©ë‹ˆë‹¤.\\n\\n4. **ë„êµ¬ í†µí•©**  \\n   - ì™¸ë¶€ API, ë°ì´í„°ë² ì´ìŠ¤, ê²€ìƒ‰ ì‹œìŠ¤í…œ ë“±ê³¼ì˜ ì—°ë™ì„ ì§€ì›í•©ë‹ˆë‹¤.  \\n   - ì˜ˆ: LLMì´ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì°¸ì¡°í•´ ë‹µë³€ì„ ìƒì„±í•˜ë„ë¡ ì„¤ê³„ ê°€ëŠ¥.\\n\\n### ì‚¬ìš© ì‚¬ë¡€\\n- **ë³µì¡í•œ ì±—ë´‡**: ì‚¬ìš©ì ì§ˆë¬¸ì— ë”°ë¼ ë™ì ìœ¼ë¡œ ëŒ€í™” ê²½ë¡œë¥¼ ë³€ê²½í•˜ëŠ” ì‹œìŠ¤í…œ.  \\n- **ì—ì´ì „íŠ¸ ì›Œí¬í”Œë¡œìš°**: LLMì´ ì—¬ëŸ¬ ë‹¨ê³„(ì˜ˆ: ë°ì´í„° ìˆ˜ì§‘ â†’ ë¶„ì„ â†’ ë³´ê³ ì„œ ìƒì„±)ë¥¼ ê±°ì³ ì‘ì—…ì„ ì™„ë£Œ.  \\n- **ë©€í‹°í”Œë ˆì´ì–´ ê²Œì„**: ìƒíƒœ ê¸°ë°˜ìœ¼ë¡œ í”Œë ˆì´ì–´ ê°„ ìƒí˜¸ì‘ìš©ì„ ê´€ë¦¬.  \\n- **RAG(Retrieval-Augmented Generation)**: ê²€ìƒ‰-ìƒì„± íŒŒì´í”„ë¼ì¸ì„ ê·¸ë˜í”„ë¡œ í‘œí˜„.\\n\\n### ê¸°ìˆ ì  ê¸°ë°˜\\n- **LangChain**ê³¼ì˜ í†µí•©: LangChainì˜ `Chain`, `Agent`, `Memory`ë¥¼ LangGraph ë…¸ë“œë¡œ í™œìš©.  \\n- **Python ì¤‘ì‹¬**: í˜„ì¬ Python ë¼ì´ë¸ŒëŸ¬ë¦¬ë§Œ ì œê³µë˜ë©°, ë‹¤ë¥¸ ì–¸ì–´ ì§€ì›ì€ ê³„íš ì¤‘ì…ë‹ˆë‹¤.  \\n- **ìƒíƒœ ì§€ì†ì„±**: JSON, ë°ì´í„°ë² ì´ìŠ¤ ë“±ì— ê·¸ë˜í”„ ìƒíƒœë¥¼ ì €ì¥í•´ ì„¸ì…˜ ê°„ ì—°ì†ì„± ìœ ì§€.\\n\\n### ì˜ˆì‹œ ì½”ë“œ (ê°„ë‹¨í•œ ê·¸ë˜í”„)\\n```python\\nfrom langgraph import State, Graph\\n\\nstate = State()\\ngraph = Graph(state)\\n\\n@graph.node\\ndef start(state: State) -> dict:\\n    return {\"next\": {\"classify\": state.get(\"input\")}}\\n\\n@graph.node\\ndef classify(state: State) -> dict:\\n    # ê°„ë‹¨í•œ ë¶„ë¥˜ ë¡œì§ ì˜ˆì‹œ\\n    if \"hello\" in state.input:\\n        return {\"next\": \"greeting\"}\\n    else:\\n        return {\"next\": \"default\"}\\n\\n@graph.node\\ndef greeting(state: State) -> dict:\\n    return {\"output\": \"Hello! How can I help you?\"}\\n\\n@graph.node\\ndef default(state: State) -> dict:\\n    return {\"output\": \"I\\'m not sure how to respond.\"}\\n\\ngraph.add_edge(\"start\", \"classify\")\\ngraph.add_edge(\"classify\", \"greeting\")\\ngraph.add_edge(\"classify\", \"default\")\\n\\n# ì‹¤í–‰\\nresult = graph.run(\"Hello there!\")\\nprint(result[\"output\"])  # ì¶œë ¥: \"Hello! How can I help you?\"\\n```\\n\\nLangGraphëŠ” LLM ì• í”Œë¦¬ì¼€ì´ì…˜ì„ **êµ¬ì¡°í™”ëœ ë°©ì‹**ìœ¼ë¡œ ì„¤ê³„í•  ìˆ˜ ìˆê²Œ í•´ì£¼ë©°, íŠ¹íˆ ìƒíƒœ ê´€ë¦¬ê°€ í•„ìš”í•œ ë³µì¡í•œ ì‹œìŠ¤í…œì— ê°•ì ì„ ê°€ì§‘ë‹ˆë‹¤. ê³µì‹ ë¬¸ì„œì™€ ì˜ˆì œ ë¦¬í¬ì§€í† ë¦¬ì—ì„œ ë” ìì„¸í•œ ì •ë³´ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 716, 'prompt_tokens': 19, 'total_tokens': 735, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'solar-pro2-250909', 'system_fingerprint': None, 'id': 'b16ce0bc-366e-4707-83cf-421a6711b221', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--8020f055-ff47-444f-8fe5-a006b245f3fa-0', usage_metadata={'input_tokens': 19, 'output_tokens': 716, 'total_tokens': 735, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# from langchain_openai import ChatOpenAI\n",
        "\n",
        "# llm = ChatOpenAI(model='gpt-4o-mini') # í…ŒìŠ¤íŠ¸ì˜ ê²½ìš°ì—ëŠ” ì‘ì€ ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤\n",
        "\n",
        "from langchain_upstage import ChatUpstage\n",
        "llm = ChatUpstage(\n",
        "        model=\"solar-pro\",\n",
        "        base_url=\"https://api.upstage.ai/v1\",\n",
        "        temperature=0.5\n",
        "    )\n",
        "print(llm)\n",
        "\n",
        "query = 'LangGraphëŠ” ë¬´ì—‡ì¸ê°€ìš”?'\n",
        "llm.invoke(query)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### LangGraphì˜ ê¸°ë³¸ê°œë…\n",
        "* `state`ëŠ” LangGraph ì—ì´ì „íŠ¸ì˜ stateë¥¼ ë‚˜íƒ€ë‚´ëŠ” ë°ì´í„° êµ¬ì¡°ì…ë‹ˆë‹¤.\n",
        "* `state`ëŠ” `TypedDict`ë¥¼ ì‚¬ìš©í•˜ì—¬ ì •ì˜ë˜ë©°, ì´ëŠ” Pythonì˜ íƒ€ì… íŒíŒ…ì„ í†µí•´ êµ¬ì¡°ë¥¼ ëª…í™•íˆ í•©ë‹ˆë‹¤.\n",
        "    * ê°„ë‹¨í•˜ê²Œ `messages`ë¼ëŠ” í•„ë“œë§Œ ìˆìŠµë‹ˆë‹¤.\n",
        "    * í•„ìš”ì— ë”°ë¼ ë‹¤ì–‘í•œ ê°’ë“¤ì„ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "* `state`ëŠ” ì—ì´ì „íŠ¸ì˜ ë™ì‘ì„ ê²°ì •í•˜ëŠ” ë° ì‚¬ìš©ë˜ë©°, ê° ë…¸ë“œì—ì„œ stateë¥¼ ì—…ë°ì´íŠ¸í•˜ê±°ë‚˜ ì°¸ì¡°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "* `state`ëŠ” LangGraphì˜ ë…¸ë“œ ê°„ì— ì „ë‹¬ë˜ë©°, ì—ì´ì „íŠ¸ì˜ state ì „ì´ë¥¼ ê´€ë¦¬í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import Annotated # íƒ€ì… íŒíŠ¸ë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•´ \n",
        "from typing_extensions import TypedDict # êµ¬ì¡°í™”ëœ ë”•ì…”ë„ˆë¦¬ íƒ€ì…ì„ ì •ì˜í•˜ê¸° ìœ„í•´ \n",
        "\n",
        "from langgraph.graph.message import add_messages \n",
        "from langchain_core.messages import AnyMessage # LangChainì—ì„œ ì‚¬ìš©í•˜ëŠ” ëª¨ë“  ì¢…ë¥˜ì˜ ë©”ì‹œì§€(ì˜ˆ: HumanMessage, AIMessage)\n",
        "\n",
        "# AgentStateëŠ” ì—ì´ì „íŠ¸ì˜ í˜„ì¬ ìƒíƒœë¥¼ ë‚˜íƒ€ë‚´ëŠ” ë”•ì…”ë„ˆë¦¬ íƒ€ì…ì„ ì •ì˜í•©ë‹ˆë‹¤.\n",
        "# TypedDictë¥¼ ì‚¬ìš©í•˜ë©´ ë”•ì…”ë„ˆë¦¬ê°€ ì–´ë–¤ í‚¤ì™€ ê°’ íƒ€ì…ì„ ê°€ì ¸ì•¼ í•˜ëŠ”ì§€ ëª…í™•í•˜ê²Œ ì§€ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "class AgentState(TypedDict):\n",
        "    # 'messages' í‚¤ëŠ” ì—ì´ì „íŠ¸ì˜ ëŒ€í™” ê¸°ë¡ì„ ì €ì¥í•©ë‹ˆë‹¤.\n",
        "    # ì´ ëª©ë¡ì—ëŠ” LangChain ë©”ì‹œì§€ ê°ì²´(AnyMessage)ê°€ ë“¤ì–´ê°‘ë‹ˆë‹¤.\n",
        "    # LangGraphê°€ ì´ ìƒíƒœë¥¼ ì²˜ë¦¬í•  ë•Œ, ìƒˆë¡œìš´ ë©”ì‹œì§€ê°€ ì¶”ê°€ë˜ë©´\n",
        "    # ê¸°ì¡´ ë©”ì‹œì§€ ëª©ë¡ì˜ ëì— ìë™ìœ¼ë¡œ ì¶”ê°€ë˜ë„ë¡(append) ì„¤ì •í•©ë‹ˆë‹¤.\n",
        "    messages: list[Annotated[AnyMessage, add_messages]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- ìœ„ì— ì„ ì–¸í•œ `AgentState`ë¥¼ í™œìš©í•˜ì—¬ `StateGraph`ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'langgraph.graph.state.StateGraph'>\n"
          ]
        }
      ],
      "source": [
        "from langgraph.graph import StateGraph\n",
        "\n",
        "graph_builder = StateGraph(AgentState)\n",
        "print(type(graph_builder))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- `graph`ì— ì¶”ê°€í•  `node`ë¥¼ ìƒì„±í•©ë‹ˆë‹¤\n",
        "-  `node`ëŠ” LangGraphì—ì„œ ì‹¤í–‰ë˜ëŠ” ê°œë³„ì ì¸ ì‘ì—… ë‹¨ìœ„ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤. \n",
        "    - ê° ë…¸ë“œëŠ” íŠ¹ì • ê¸°ëŠ¥ì„ ìˆ˜í–‰í•˜ëŠ” ë…ë¦½ì ì¸ ì»´í¬ë„ŒíŠ¸ë¡œ, ì˜ˆë¥¼ ë“¤ì–´ í…ìŠ¤íŠ¸ ìƒì„±, ë°ì´í„° ì²˜ë¦¬, ë˜ëŠ” ì˜ì‚¬ ê²°ì •ê³¼ ê°™ì€ ì‘ì—…ì„ ë‹´ë‹¹í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "    - `node`ëŠ” ê¸°ë³¸ì ìœ¼ë¡œ í•¨ìˆ˜(function)ë¡œ ì •ì˜ë˜ê³ , ë’¤ì—ì„œ ë‹¤ë£¨ì§€ë§Œ ë‹¤ë¥¸ ì—ì´ì „íŠ¸(agent)ë¥¼ í™œìš©í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Node ì—­í•  í•˜ëŠ” í•¨ìˆ˜ì˜ ì¸ìë¡œ state ê°ì²´ë¥¼ ì‚¬ìš©í•¨ - LLMì„ í˜¸ì¶œí•˜ëŠ” ë…¸ë“œ\n",
        "def generate(state: AgentState) -> AgentState:\n",
        "    \"\"\"\n",
        "    `generate` ë…¸ë“œëŠ” ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë°›ì•„ì„œ ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ë…¸ë“œì…ë‹ˆë‹¤.\n",
        "    \"\"\"\n",
        "    messages = state['messages']\n",
        "    ai_message = llm.invoke(messages)\n",
        "    return {'messages': [ai_message]}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- `node`ë¥¼ ìƒì„±í•œ í›„ì— `edge`ë¡œ ì—°ê²°í•©ë‹ˆë‹¤\n",
        "- `edge`ëŠ” ë…¸ë“œë“¤ ì‚¬ì´ì˜ ì—°ê²°ì„ ë‚˜íƒ€ë‚´ë©°, ë°ì´í„°ì™€ ì œì–´ íë¦„ì˜ ê²½ë¡œë¥¼ ì •ì˜í•©ë‹ˆë‹¤. \n",
        "    - ì—£ì§€ë¥¼ í†µí•´ í•œ ë…¸ë“œì˜ ì¶œë ¥ì´ ë‹¤ìŒ ë…¸ë“œì˜ ì…ë ¥ìœ¼ë¡œ ì „ë‹¬ë˜ì–´, ì „ì²´ì ì¸ ì›Œí¬í”Œë¡œìš°ê°€ í˜•ì„±ë©ë‹ˆë‹¤.\n",
        "    - `node`ì™€ `edge`ì˜ ì¡°í•©ì€ ë°©í–¥ì„± ê·¸ë˜í”„(Directed Graph)ë¥¼ í˜•ì„±í•˜ë©°, ì´ë¥¼ í†µí•´ ë³µì¡í•œ AI ì—ì´ì „íŠ¸ì˜ í–‰ë™ íë¦„ì„ êµ¬ì¡°í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x27fcc67f7d0>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# LLMì„ í˜¸ì¶œí•˜ëŠ” generateí•¨ìˆ˜ë¥¼ Nodeë¡œ ì •ì˜í•¨\n",
        "graph_builder.add_node('generate', generate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- ëª¨ë“  ê·¸ë˜í”„ëŠ” `START(ì‹œì‘)`ì™€ `END(ì¢…ë£Œ)`ê°€ ìˆìŠµë‹ˆë‹¤\n",
        "    - `END`ë¥¼ explicití•˜ê²Œ ì„ ì–¸í•˜ì§€ ì•ŠëŠ” ê²½ìš°ë„ ì¢…ì¢… ìˆì§€ë§Œ, ê°€ë…ì„±ì„ ìœ„í•´ ì‘ì„±í•´ì£¼ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x27fcc67f7d0>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langgraph.graph import START, END\n",
        "\n",
        "graph_builder.add_edge(START, 'generate')\n",
        "graph_builder.add_edge('generate', END)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- `node`ë¥¼ ìƒì„±í•˜ê³  `edge`ë¡œ ì—°ê²°í•œ í›„ì— `compile` ë©”ì„œë“œë¥¼ í˜¸ì¶œí•˜ì—¬ `Graph`ë¥¼ ìƒì„±í•©ë‹ˆë‹¤"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'langgraph.graph.state.CompiledStateGraph'>\n"
          ]
        }
      ],
      "source": [
        "graph = graph_builder.compile()\n",
        "print(type(graph))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- `compile` í›„ì—ëŠ” ê·¸ë˜í”„ë¥¼ ì‹œê°í™”í•˜ì—¬ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤\n",
        "- ì˜ë„í•œëŒ€ë¡œ ê·¸ë˜í”„ê°€ ìƒì„±ëëŠ”ì§€ í™•ì¸í•˜ëŠ” ìŠµê´€ì„ ê¸°ë¥´ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤\n",
        "    - `git`ì—ì„œ ì½”ë“œ ì‘ì—…ë¬¼ì„ commití•˜ê¸° ì „ì— `git diff`ë¥¼ í†µí•´ ë³€ê²½ì‚¬í•­ì„ í™•ì¸í•˜ëŠ” ê²ƒê³¼ ê°™ìŠµë‹ˆë‹¤"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#from IPython.display import display, Image\n",
        "\n",
        "#display(Image(graph.get_graph().draw_mermaid_png(max_retries=5, retry_delay=2.0)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mermaid Code:\n",
            "---\n",
            "config:\n",
            "  flowchart:\n",
            "    curve: linear\n",
            "---\n",
            "graph TD;\n",
            "\t__start__([<p>__start__</p>]):::first\n",
            "\tgenerate(generate)\n",
            "\t__end__([<p>__end__</p>]):::last\n",
            "\t__start__ --> generate;\n",
            "\tgenerate --> __end__;\n",
            "\tclassDef default fill:#f2f0ff,line-height:1.2\n",
            "\tclassDef first fill-opacity:0\n",
            "\tclassDef last fill:#bfb6fc\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ëŒ€ì²´ ë°©ë²•\n",
        "mermaid_code = graph.get_graph().draw_mermaid()\n",
        "print(\"Mermaid Code:\")\n",
        "print(mermaid_code)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* https://mermaid.live/ ì—ì„œ  mermain_code ë¡œ ì§ì ‘ í™•ì¸í•œë‹¤.\n",
        "\n",
        "* [Graph ì´ë¯¸ì§€](https://mermaidchart.com/play?utm_source=mermaid_live_editor&utm_medium=share#pako:eNpVkN1ugzAMhV8FeTetBCzQ8tO06s36CLvaMlUpOBAJAgpBWlf13RfSlq25iR2f78T2BYquRKBQad7X3vthyxQzx-NguLbX4nPX7-ds99rvv5aUUiH1YCZhhQo1N7h4BMsbjqqcYRfPaMNv5GzqBcHee-Db_6aucuddobDwcEDhlSj42BhPyKahLyIWRAi_kQqDGmVVGxqF8RPgGnbyoOt5Ic2ZkifB1Nbd7iROqSiYAt8uRZZAjR7RhxZ1y6cULkx5HgNTY4sMqA3v_TBg6mqxnquPrmsfpO7GqgYqeDPYbOxLO9tBcrvxP4kdEvVbNyoDNE2cBdALfANdkTRMo2QTJ2meb6JstfbhbJ_TMIoTQsg6yUmU5ZurDz_uUxLm2VSYT3T9BaY8oOc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------------------------\n",
            "<class 'dict'>\n",
            "content='**LangGraph**ì™€ **LangChain**ì€ ëª¨ë‘ LLM(Large Language Model)ì„ í™œìš©í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œì„ ìœ„í•œ í”„ë ˆì„ì›Œí¬ì´ì§€ë§Œ, ëª©ì ê³¼ ê¸°ëŠ¥ì—ì„œ ì°¨ì´ê°€ ìˆìŠµë‹ˆë‹¤.  \\n\\n### **1. LangChainì´ë€?**  \\n- **ëª©ì **: LLMì„ í™œìš©í•œ ë‹¤ì–‘í•œ ì• í”Œë¦¬ì¼€ì´ì…˜(ì±—ë´‡, ë¬¸ì„œ ë¶„ì„, ì—ì´ì „íŠ¸ ë“±)ì„ **ëª¨ë“ˆì‹ìœ¼ë¡œ êµ¬ì¶•**í•˜ê¸° ìœ„í•œ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.  \\n- **ì£¼ìš” ê¸°ëŠ¥**:  \\n  - **ëª¨ë“ˆí™”ëœ êµ¬ì„± ìš”ì†Œ** (ì˜ˆ: í”„ë¡¬í”„íŠ¸ ê´€ë¦¬, ë©”ëª¨ë¦¬, ì²´ì¸, ë„êµ¬ ì‚¬ìš©, ë²¡í„° DB ì—°ë™) ì œê³µ.  \\n  - **ìœ ì—°í•œ íŒŒì´í”„ë¼ì¸ êµ¬ì¶•** (ì˜ˆ: \"ì§ˆë¬¸ â†’ ê²€ìƒ‰ â†’ ì‘ë‹µ ìƒì„±\"ê³¼ ê°™ì€ ë‹¤ì¤‘ ë‹¨ê³„ ì‘ì—…).  \\n  - **LangSmith**ì™€ ê°™ì€ ë””ë²„ê¹…/ëª¨ë‹ˆí„°ë§ ë„êµ¬ ì§€ì›.  \\n- **ì í•©í•œ ì‚¬ìš© ì‚¬ë¡€**:  \\n  - ê°„ë‹¨í•œ ì±—ë´‡, RAG(Retrieval-Augmented Generation), ë©€í‹°ëª¨ë‹¬ ì• í”Œë¦¬ì¼€ì´ì…˜ ë“±.  \\n\\n> ğŸ“Œ **LangChain = LLM ê¸°ë°˜ ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ \"ë ˆê³  ë¸”ë¡\" ê°™ì€ ë„êµ¬**  \\n\\n---\\n\\n### **2. LangGraphë€?**  \\n- **ëª©ì **: **ë³µì¡í•œ ìƒíƒœ(State)ê°€ í•„ìš”í•œ ë‹¤ë‹¨ê³„ ì‘ì—…** (ì˜ˆ: ëŒ€í™” ìƒíƒœ ê´€ë¦¬, ì›Œí¬í”Œë¡œìš° ìë™í™”)ì„ ìœ„í•œ **ê·¸ë˜í”„ ê¸°ë°˜ í”„ë ˆì„ì›Œí¬**ì…ë‹ˆë‹¤.  \\n- **ì£¼ìš” ê¸°ëŠ¥**:  \\n  - **ìƒíƒœ(State) ì¶”ì **: ê° ë…¸ë“œ/ì—£ì§€ì—ì„œ ë©”ëª¨ë¦¬ë‚˜ ì»¨í…ìŠ¤íŠ¸ë¥¼ ìœ ì§€í•˜ë©° ì‘ì—…ì„ ì—°ê²°í•©ë‹ˆë‹¤.  \\n  - **ë¹„ë™ê¸°/ë™ê¸° ì›Œí¬í”Œë¡œìš° ì§€ì›**: ì—¬ëŸ¬ ì—ì´ì „íŠ¸ê°€ í˜‘ì—…í•˜ê±°ë‚˜ ìˆœì°¨ì  ì‘ì—…ì´ í•„ìš”í•œ ì‹œë‚˜ë¦¬ì˜¤ì— ì í•©í•©ë‹ˆë‹¤.  \\n  - **LangChainê³¼ì˜ í†µí•©**: LangChainì˜ ì²´ì¸/ë„êµ¬ë¥¼ ê·¸ë˜í”„ ë…¸ë“œë¡œ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  \\n- **ì í•©í•œ ì‚¬ìš© ì‚¬ë¡€**:  \\n  - ë‹¤ë‹¨ê³„ ëŒ€í™” ì‹œìŠ¤í…œ (ì˜ˆ: \"ê³ ê° ì§€ì› â†’ ê²°ì œ í™•ì¸ â†’ ì˜ˆì•½ ì™„ë£Œ\").  \\n  - ë³µí•© ì—ì´ì „íŠ¸ í˜‘ì—… (ì˜ˆ: \"ì—°êµ¬ì› ì—ì´ì „íŠ¸ â†’ ë°ì´í„° ë¶„ì„ ì—ì´ì „íŠ¸ â†’ ë³´ê³ ì„œ ìƒì„± ì—ì´ì „íŠ¸\").  \\n\\n> ğŸ“Œ **LangGraph = \"ìƒíƒœ ë¨¸ì‹  + ê·¸ë˜í”„ êµ¬ì¡°\"ë¡œ ë³µì¡í•œ íë¦„ì„ ê´€ë¦¬í•˜ëŠ” LangChainì˜ í™•ì¥**  \\n\\n---\\n\\n### **3. ì£¼ìš” ì°¨ì´ì  ìš”ì•½**  \\n| íŠ¹ì§•                | LangChain                          | LangGraph                          |\\n|---------------------|------------------------------------|------------------------------------|\\n| **ì£¼ìš” ëª©ì **       | ëª¨ë“ˆì‹ LLM ì• í”Œë¦¬ì¼€ì´ì…˜ êµ¬ì¶•       | ìƒíƒœ ê¸°ë°˜ ë‹¤ë‹¨ê³„ ì›Œí¬í”Œë¡œìš° ê´€ë¦¬    |\\n| **êµ¬ì¡°**            | ì„ í˜• ë˜ëŠ” ë¶„ê¸°í˜• ì²´ì¸              | ê·¸ë˜í”„/ìƒíƒœ ë¨¸ì‹  êµ¬ì¡°              |\\n| **ìƒíƒœ ê´€ë¦¬**       | ì œí•œì  (ë©”ëª¨ë¦¬ ëª¨ë“ˆë¡œ ë³´ì™„)        | ë‚´ì¥ ìƒíƒœ ì¶”ì  ë° ì „ì´ ì§€ì›        |\\n| **ì í•©í•œ ì‘ì—…**     | ë‹¨ì¼/ê°„ë‹¨í•œ ë‹¤ì¤‘ ë‹¨ê³„ ì‘ì—…         | ë³µì¡í•œ ë‹¤ë‹¨ê³„ í˜‘ì—… ë˜ëŠ” ëŒ€í™” ì‹œìŠ¤í…œ |\\n| **í†µí•© ê´€ê³„**       | ë…ë¦½ì  ì‚¬ìš© ê°€ëŠ¥                   | LangChain ì»´í¬ë„ŒíŠ¸ë¥¼ ë…¸ë“œë¡œ í™œìš©   |\\n\\n---\\n\\n### **4. ì˜ˆì‹œ ì‹œë‚˜ë¦¬ì˜¤**  \\n- **LangChainë§Œ ì‚¬ìš©**:  \\n  - \"ì‚¬ìš©ì ì§ˆë¬¸ â†’ ë¬¸ì„œ ê²€ìƒ‰ â†’ LLM ì‘ë‹µ ìƒì„±\"ê³¼ ê°™ì€ ì„ í˜• RAG íŒŒì´í”„ë¼ì¸.  \\n- **LangGraph + LangChain**:  \\n  - \"ê³ ê°ì´ ì˜ˆì•½ ìš”ì²­ â†’ ì‹œìŠ¤í…œì´ ì˜ˆì•½ ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸ â†’ ê²°ì œ ì²˜ë¦¬ â†’ í™•ì¸ ì´ë©”ì¼ ë°œì†¡\"ê³¼ ê°™ì€ ìƒíƒœ ì „ì´ ì›Œí¬í”Œë¡œìš°.  \\n\\nLangGraphëŠ” LangChainì˜ ìƒìœ„ í˜¸í™˜ ë„êµ¬ë¡œ, **ë³µì¡í•œ ìƒíƒœ ê´€ë¦¬ê°€ í•„ìš”í•  ë•Œ** ì„ íƒí•˜ë©´ ë©ë‹ˆë‹¤. ê¸°ë³¸ LLM ì• í”Œë¦¬ì¼€ì´ì…˜ì—ëŠ” LangChainë§Œìœ¼ë¡œë„ ì¶©ë¶„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 653, 'prompt_tokens': 25, 'total_tokens': 678, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'solar-pro2-250909', 'system_fingerprint': None, 'id': '47ea5c5f-b31a-4eec-9321-c9d5c1c4c69d', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None} id='run--fae389ed-d8c6-4844-b82b-aa84855614d5-0' usage_metadata={'input_tokens': 25, 'output_tokens': 653, 'total_tokens': 678, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "query = 'LangGraphëŠ” ë¬´ì—‡ì¸ê°€ìš”? LangChainê³¼ì˜ ì°¨ì´ì ì€ ë¬´ì—‡ì¸ê°€ìš”?'\n",
        "initial_state = {'messages': [HumanMessage(query)]}\n",
        "result = graph.invoke(initial_state)\n",
        "\n",
        "print(\"-\"*30)\n",
        "print(type(result))\n",
        "print(result['messages'][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2ê°œì˜ AI ì—ì´ì „íŠ¸ í˜‘ë ¥í•˜ê¸°\n",
        "\n",
        "* ì²« ë²ˆì§¸ AI ì—ì´ì „íŠ¸\n",
        "    * ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë¶„ì„í•˜ê³  í•µì‹¬ í‚¤ì›Œë“œì™€ ë°°ê²½ ì •ë³´ ì¶”ê°€í•˜ëŠ” ì—­í• \n",
        "* ë‘ ë²ˆì§¸ AI ì—ì´ì „íŠ¸\n",
        "    * ì²« ë²ˆì§¸ ì—ì´ì „íŠ¸ê°€ ì œê³µí•˜ëŠ” ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìì„¸í•œ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì—­í• "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langgraph.graph import StateGraph\n",
        "\n",
        "from pprint import pprint\n",
        "\n",
        "# ì²«ë²ˆì§¸ AIì—ì´ì „íŠ¸\n",
        "def agent_1(state):\n",
        "    \"\"\" \n",
        "        ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë¶„ì„í•˜ê³  í•µì‹¬ í‚¤ì›Œë“œì™€ ë°°ê²½ ì •ë³´ ì¶”ê°€í•˜ëŠ” ì—­í• \n",
        "    \"\"\"\n",
        "    query = state['query']\n",
        "    keywords = llm.invoke(f'ì§ˆë¬¸: {query}\\nì´ ì§ˆë¬¸ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œë¥¼ 3~5ê°œ ì¶”ì¶œí•´ ì£¼ì„¸ìš”.')\n",
        "\n",
        "     # ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ë°°ê²½ ì •ë³´ ì œê³µ\n",
        "    background_info = llm.invoke(f\"ì§ˆë¬¸: {query}\\nì´ ì§ˆë¬¸ì„ ì´í•´í•˜ëŠ” ë° ë„ì›€ì´ ë  ë§Œí•œ ì¶”ê°€ ì •ë³´ë¥¼ ì œê³µí•´ ì£¼ì„¸ìš”.\")\n",
        "\n",
        "    print(f\"\\n[Agent 1] ì›ë³¸ ì§ˆë¬¸: {query}\")\n",
        "    print(f\"[Agent 1] í•µì‹¬ í‚¤ì›Œë“œ: {keywords}\")\n",
        "    print(f\"[Agent 1] ë°°ê²½ ì •ë³´: {background_info}\\n\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "mylangchain-app-SBe-Yh6W-py3.12",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
